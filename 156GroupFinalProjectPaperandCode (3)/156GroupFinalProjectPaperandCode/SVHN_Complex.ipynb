{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU-rB0bAnULC"
      },
      "outputs": [],
      "source": [
        " #get all our libraries\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from scipy.io import loadmat\n",
        "import scipy.io\n",
        "\n"
      ],
      "id": "xU-rB0bAnULC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD3VB098ZdFW"
      },
      "outputs": [],
      "source": [
        "#here we keep the entire history of state sequences and corresponding accuracies\n",
        "all_acc=[]"
      ],
      "id": "eD3VB098ZdFW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58a3579b-8677-4942-bfa9-deadc865e64a",
        "outputId": "46b6da8a-ed37-4cf9-8b6b-b6b7c05c27b1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "#we initialize our sequence space so that each layer type may appear at each layer number\n",
        "#its a dictionary so that each tuple can be later indexed in our Q-table\n",
        "states = {(0, 'i', 1):0,\n",
        "          (1, 'c1', 1):1,\n",
        "          (1, 'c2', 1):2,\n",
        "          (1, 'c3', 1):3,\n",
        "          (1, 'c4', 1):4,\n",
        "          (1, 'p1', 1):5,\n",
        "          (1, 'p2', 1):6,\n",
        "          (1, 'd1', 0):7,\n",
        "          (1, 'd2', 0):8,\n",
        "          (1, 't', 0):9,\n",
        "          (2, 'c1', 1):10,\n",
        "          (2, 'c2', 1):11,\n",
        "          (2, 'c3', 1):12,\n",
        "          (2, 'c4', 1):13,\n",
        "          (2, 'p1', 1):14,\n",
        "          (2, 'p2', 1):15,\n",
        "          (2, 'd1', 0):16,\n",
        "          (2, 'd2', 0):17,\n",
        "          (2, 't', 0):18,\n",
        "          (3, 'c1', 1):19,\n",
        "          (3, 'c2', 1):20,\n",
        "          (3, 'c3', 1):21,\n",
        "          (3, 'c4', 1):21,\n",
        "          (3, 'p1', 1):22,\n",
        "          (3, 'p2', 1):23,\n",
        "          (3, 'd1', 0):24,\n",
        "          (3, 'd2', 0):25,\n",
        "          (3, 't', 0):26,\n",
        "          (4, 'c1', 1):27,\n",
        "          (4, 'c2', 1):28,\n",
        "          (4, 'c3', 1):29,\n",
        "          (4, 'c4', 1):30,\n",
        "          (4, 'p1', 1):31,\n",
        "          (4, 'p2', 1):32,\n",
        "          (4, 'd1', 0):33,\n",
        "          (4, 'd2', 0):34,\n",
        "          (4, 't', 0):35,\n",
        "          (5, 'c1', 1):36,\n",
        "          (5, 'c2', 1):37,\n",
        "          (5, 'c3', 1):38,\n",
        "          (5, 'c4', 1):39,\n",
        "          (5, 'p1', 1):40,\n",
        "          (5, 'p2', 1):41,\n",
        "          (5, 'd1', 0):42,\n",
        "          (5, 'd2', 0):43,\n",
        "          (5, 't', 0):44,\n",
        "          (6, 'c1', 1):45,\n",
        "          (6, 'c2', 1):46,\n",
        "          (6, 'c3', 1):47,\n",
        "          (6, 'c4', 1):48,\n",
        "          (6, 'p1', 1):49,\n",
        "          (6, 'p2', 1):50,\n",
        "          (6, 'd1', 0):51,\n",
        "          (6, 'd2', 0):52,\n",
        "          (6, 't', 0):53,\n",
        "          (7, 'c1', 1):54,\n",
        "          (7, 'c2', 1):55,\n",
        "          (7, 'c3', 1):56,\n",
        "          (7, 'c4', 1):57,\n",
        "          (7, 'p1', 1):58,\n",
        "          (7, 'p2', 1):59,\n",
        "          (7, 'd1', 0):60,\n",
        "          (7, 'd2', 0):61,\n",
        "          (7, 't', 0):62,\n",
        "          (8, 'c1', 1):63,\n",
        "          (8, 'c2', 1):64,\n",
        "          (8, 'c3', 1):65,\n",
        "          (8, 'c4', 1):66,\n",
        "          (8, 'p1', 1):67,\n",
        "          (8, 'p2', 1):68,\n",
        "          (8, 'd1', 0):69,\n",
        "          (8, 'd2', 0):70,\n",
        "          (8, 't', 0):71,\n",
        "          (9, 't', 0):72\n",
        "          }\n",
        "#we initialize all the layer types that we can choose as our actions. They are also indexed for use in Q-table.\n",
        "#note that input layer type'i' is not included\n",
        "actions = {'c1':0, 'c2':1, 'c3':2, 'c4':3, 'p1':4, 'p2':5, 'd1':6, 'd2':7, 't':8 }\n",
        "\n",
        "alpha = 0.01 #Q-learning rate\n",
        "\n",
        "num_states = len(states) #creates an integer that is the length of all possible states, that we use to initialize the Q-table\n",
        "num_actions = len(actions) #creates an integer that is the length of all possible actions, that we use to initialize the Q-table\n",
        "\n",
        "Q_table = np.zeros((num_states, num_actions)) #initialize Q-table\n",
        "print(Q_table)"
      ],
      "id": "58a3579b-8677-4942-bfa9-deadc865e64a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xg7rjOGtxso",
        "outputId": "6d0205dd-ea8d-4579-fb6a-bab3e2598624",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.5 0.5]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0. ]]\n"
          ]
        }
      ],
      "source": [
        "#we initialize the Q table to reflect the permissible actions\n",
        "#non-permissible actions will be zero in the Q-table below\n",
        "for i in range(len(states)-1):\n",
        "  if (list (states.keys())[i][2]==0):\n",
        "    Q_table[i][6]=.5\n",
        "    Q_table[i][7]=.5\n",
        "    Q_table[i][8]=.5\n",
        "  else:\n",
        "    Q_table[i][0]=.5\n",
        "    Q_table[i][1]=.5\n",
        "    Q_table[i][2]=.5\n",
        "    Q_table[i][3]=.5\n",
        "    Q_table[i][4]=.5\n",
        "    Q_table[i][5]=.5\n",
        "    Q_table[i][6]=.5\n",
        "    Q_table[i][7]=.5\n",
        "    Q_table[i][8]=.5\n",
        "print (Q_table)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "3Xg7rjOGtxso"
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "#create a directory for the data\n",
        "os.makedirs(\"svhn_dataset\", exist_ok=True)\n",
        "\n",
        "#download SVHN dataset files\n",
        "urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\", \"svhn_dataset/train_32x32.mat\")\n",
        "urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\", \"svhn_dataset/test_32x32.mat\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAdtMREkLQJb",
        "outputId": "d9db4f66-33d1-4add-d6b8-0b2f0a2981ff",
        "collapsed": true
      },
      "id": "zAdtMREkLQJb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in svhn_dataset directory:\n",
            "['train_32x32.mat', 'test_32x32.mat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVHN Data"
      ],
      "metadata": {
        "id": "4azqOcZTDOlH"
      },
      "id": "4azqOcZTDOlH"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#initialize our desired values for batch size, number of classes, and epochs used in each run through a CNN\n",
        "batch_size=128\n",
        "num_classes=10\n",
        "epochs= 10\n",
        "\n",
        "im_rows,img_cols,img_chan=32,32,3 #ensure we are using the correct dimensions of the SVHN dataset images\n",
        "\n",
        "#load training and testing data\n",
        "train_data = scipy.io.loadmat(\"svhn_dataset/train_32x32.mat\")\n",
        "test_data = scipy.io.loadmat(\"svhn_dataset/test_32x32.mat\")\n",
        "\n",
        "#extract images and labels from the loaded data\n",
        "x_train, y_train = train_data['X'], train_data['y']\n",
        "x_test, y_test = test_data['X'], test_data['y']\n",
        "\n",
        "#transpose the image data to have the correct dimensions\n",
        "x_train = x_train.transpose((3, 0, 1, 2))\n",
        "x_test = x_test.transpose((3, 0, 1, 2))\n",
        "\n",
        "#turn it into vector\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "#Make the 10 value be a 0 as it\n",
        "y_train = [0 if label == 10 else label for label in y_train]\n",
        "y_test = [0 if label == 10 else label for label in y_test]\n",
        "\n",
        "y_train = to_categorical(y_train,num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Print shapes of the datasets\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-zjPT1sKq3X",
        "outputId": "3528b3c7-c73c-4ff5-8cc9-17148c1cc9e5",
        "collapsed": true
      },
      "id": "G-zjPT1sKq3X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (73257, 32, 32, 3)\n",
            "y_train shape: (73257, 10)\n",
            "x_test shape: (26032, 32, 32, 3)\n",
            "y_test shape: (26032, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxcKsKrIefwE"
      },
      "outputs": [],
      "source": [
        "#this function takes in the previous state and action it returns the new state chosen\n",
        "#it uses the indicators to ensure that once the network has reached a dense or terminal layer, -\n",
        "#it cannot return to a convolutional or maxpooling layer\n",
        "def transition(state, action):\n",
        "  layer_num, layer_type, indicator = state\n",
        "  layer_num += 1\n",
        "  if action in ['d1','d2' ,'t']:\n",
        "    indicator = 0\n",
        "  else:\n",
        "    indicator = 1\n",
        "  new_state = (layer_num, action, indicator)\n",
        "  return new_state\n",
        "\n",
        "#this function returns the permissible actions at a given state\n",
        "#the indicator state variable indicates whether it is possible for the next layer to be convolutional or maxpooling\n",
        "#1 indicates that all layers types are still permissibile\n",
        "#0 indicates that only dense layers or the termination layer are allowed\n",
        "#the first if statements ensures that there is a max number of 8 layers allowed\n",
        "def permissible_actions(state):\n",
        "  layer_num, layer_type, indicator = state\n",
        "  if layer_num==8:\n",
        "    actions=['t']\n",
        "  elif layer_num == 5:\n",
        "    actions= ['d1','d2','t']\n",
        "  else:\n",
        "    if indicator==0:\n",
        "      actions = ['d1', 'd2', 't']\n",
        "    else:\n",
        "      actions = ['c1', 'c2','c3', 'c4', 'p1','p2', 'd1','d2', 't']\n",
        "\n",
        "  return actions\n",
        "\n",
        "#this function implements a part of the Q-learning algorithm that samples a new network architecture based on the current Q-table\n",
        "#it starts from an initial state and iteratively selects actions until a terminal action is chosen, forming a path through the state-action space.\n",
        "#the selection of actions is based on an epsilon-greedy strategy, which balances exploration (random action selection) -\n",
        "#-and exploitation (choosing the action with the highest expected reward, based on the Q-table)\n",
        "def sample_new_network(epsilon, Q_table):\n",
        "  state_seqn = [(0, 'i',1)]\n",
        "  action_seqn = []\n",
        "\n",
        "  while (action_seqn==[] or action_seqn[-1]!='t'):\n",
        "    beta = random.random()\n",
        "    if beta > epsilon:\n",
        "      state = (states.get(state_seqn[-1]))\n",
        "      permissible_indices = []\n",
        "      for i in permissible_actions(state_seqn[-1]):\n",
        "        permissible_indices.append(actions.get(i))\n",
        "      q_values = list(Q_table[state])\n",
        "      permissible_q_values = [q_values[i] for i in permissible_indices]\n",
        "      max_action = max(permissible_q_values)\n",
        "      max_action_index = permissible_q_values.index(max_action)+(len(q_values)-len(permissible_q_values))\n",
        "      u = list(actions.keys())[max_action_index]\n",
        "      s = transition(state_seqn[-1], u)\n",
        "    else:\n",
        "      u = random.choice(permissible_actions(state_seqn[-1]))\n",
        "      s = transition(state_seqn[-1], u)\n",
        "    action_seqn.append(u)\n",
        "    if u!='t':\n",
        "      state_seqn.append(s)\n",
        "\n",
        "  return state_seqn, action_seqn\n",
        "#this function updates Q-values based on the received accuracy of the sampled network\n",
        "#it iterate backwards through the state-action sequence to update the Q-values for all state-action pairs-\n",
        "#-which allows the algorithm to propagate the accuracy information back to the initial states.\n",
        "def update_q_values(Q, state_seqn, action_seqn, accuracy):\n",
        "    Q[states.get(state_seqn[-1])][actions.get(action_seqn[-1])] = (1 - alpha) * Q[states.get(state_seqn[-1])][actions.get(action_seqn[-1])] + alpha * accuracy\n",
        "    for i in range(len(state_seqn) - 2, -1, -1):\n",
        "        best_future_q = max(Q[states.get(state_seqn[i])][actions.get(future_action)] for future_action in permissible_actions(state_seqn[i+1]))\n",
        "        Q[states.get(state_seqn[i])][actions.get(action_seqn[i])] = (1 - alpha) * Q[states.get(state_seqn[i])][actions.get(action_seqn[i])] + alpha * best_future_q\n",
        "\n",
        "\n"
      ],
      "id": "CxcKsKrIefwE"
    },
    {
      "cell_type": "code",
      "source": [
        "import gc #imports a garbage collector that let us delete the cache"
      ],
      "metadata": {
        "id": "9zW8YbQ2YiIY"
      },
      "id": "9zW8YbQ2YiIY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKrxOex0oCOj"
      },
      "outputs": [],
      "source": [
        "#this function creates the actual convolution network by adding the layers given by the sequence of chosen states by the agent\n",
        "#the first double-if statement is in place for time efficiency, so that if a state sequence has already appeared in the-\n",
        "#-model we just return the accuracy of the episode instead of rerunning that CNN\n",
        "#this function is where we choose what exact layers we want the agent to choose from\n",
        "#finally, it compiles the given CNN, and compares the output to the true categories so as to obtain an accuracy score\n",
        "def train(state_seqn):\n",
        "  if len(all_acc)>0:\n",
        "    first_elements = [x[0] for x in all_acc]\n",
        "    if state_seqn in first_elements:\n",
        "      return all_acc[first_elements.index(state_seqn)][1]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(keras.Input(shape=(32,32,3)))\n",
        "  if len(state_seqn)==1:\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='Softmax', input_shape=(32, 32, 3)))\n",
        "  else:\n",
        "      counter =0\n",
        "\n",
        "      for state in state_seqn[1:]:\n",
        "        if state[1] == 'c1':\n",
        "          model.add(Conv2D(32, kernel_size= (2, 2), padding='same',activation='relu'))\n",
        "        elif state[1] == 'c2':\n",
        "          model.add(Conv2D(64, kernel_size= (2, 2), padding='same',activation='relu'))\n",
        "        elif state[1] == 'c3':\n",
        "          model.add(Conv2D(32, kernel_size= (3, 3), padding='same',activation='relu'))\n",
        "        elif state[1] == 'c4':\n",
        "          model.add(Conv2D(64, kernel_size= (3, 3), padding='same',activation='relu'))\n",
        "        elif state[1] == 'p1':\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "        elif state[1] == 'p2':\n",
        "          model.add(MaxPooling2D(pool_size=(3, 3),padding='same'))\n",
        "        elif state[1] == 'd1':\n",
        "          model.add(Flatten())\n",
        "          model.add(Dense(128, activation='relu'))\n",
        "        elif state[1] == 'd2':\n",
        "          model.add(Flatten())\n",
        "          model.add(Dense(64, activation='relu'))\n",
        "        if (counter%2 == 0):\n",
        "          model.add(Dropout(0.2))\n",
        "        counter+=1\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(learning_rate = 1e-2),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=0,\n",
        "            validation_data=(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "  del model\n",
        "  gc.collect()\n",
        "  keras.backend.clear_session()\n",
        "  return score[1]\n",
        "\n",
        "\n"
      ],
      "id": "AKrxOex0oCOj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTUJhFf0FIU6"
      },
      "outputs": [],
      "source": [
        "#this is the main function of our Q-learning model that uses all of the functions created above\n",
        "#the first for loop runs the episodes where for each a new neural network architecture is sampled-\n",
        "#deciding the architecture based on the current Q-table and the exploration rate\n",
        "#the second for loop implements the use of a replay memory for updating Q-values multiple times-\n",
        "#-within each episode which allows for improved stability and efficiency of reinforcement learning algorithms\n",
        "\n",
        "def meta_qnn_algorithm(epsilon, m=10, k=7):\n",
        "    \"\"\"MetaQNN main algorithm.\"\"\"\n",
        "    SS_acc_list=[()]\n",
        "    replay_memory = []\n",
        "\n",
        "\n",
        "    for episode in range(1, m + 1):\n",
        "        state_seqn, action_seqn = sample_new_network(epsilon, Q_table)\n",
        "        accuracy = train(state_seqn)\n",
        "\n",
        "        tup=(state_seqn,accuracy)\n",
        "        SS_acc_list=[]\n",
        "        SS_acc_list.append(tup)\n",
        "        replay_memory.append((state_seqn, action_seqn, accuracy))\n",
        "        all_acc.append(tup)\n",
        "\n",
        "        for memory in range(1, k+1):\n",
        "            Ssample, Usample, ACCsample = random.choice(replay_memory)\n",
        "            update_q_values(Q_table, Ssample, Usample, ACCsample)\n",
        "    print(epsilon)"
      ],
      "id": "iTUJhFf0FIU6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDprPwlKxC24",
        "outputId": "d0eb61ae-8ef0-48d0-a043-d41cb22cbe9d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "573/573 [==============================] - 7s 6ms/step - loss: 2.2510 - accuracy: 0.1824 - val_loss: 2.2323 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2315 - accuracy: 0.1977 - val_loss: 2.2017 - val_accuracy: 0.2217\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1981 - accuracy: 0.2259 - val_loss: 2.1566 - val_accuracy: 0.2533\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1464 - accuracy: 0.2599 - val_loss: 2.0899 - val_accuracy: 0.3016\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0764 - accuracy: 0.2949 - val_loss: 2.0127 - val_accuracy: 0.3262\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9933 - accuracy: 0.3294 - val_loss: 1.9167 - val_accuracy: 0.3924\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9058 - accuracy: 0.3618 - val_loss: 1.8288 - val_accuracy: 0.4077\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.8269 - accuracy: 0.3905 - val_loss: 1.7542 - val_accuracy: 0.4299\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7570 - accuracy: 0.4142 - val_loss: 1.6791 - val_accuracy: 0.4681\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6990 - accuracy: 0.4342 - val_loss: 1.6376 - val_accuracy: 0.4775\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.4164 - accuracy: 0.1093 - val_loss: 2.2665 - val_accuracy: 0.1630\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3248 - accuracy: 0.1473 - val_loss: 2.2562 - val_accuracy: 0.1731\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3205 - accuracy: 0.1495 - val_loss: 2.2547 - val_accuracy: 0.1736\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3184 - accuracy: 0.1507 - val_loss: 2.2532 - val_accuracy: 0.1744\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3162 - accuracy: 0.1521 - val_loss: 2.2522 - val_accuracy: 0.1761\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3169 - accuracy: 0.1512 - val_loss: 2.2504 - val_accuracy: 0.1797\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3127 - accuracy: 0.1530 - val_loss: 2.2493 - val_accuracy: 0.1826\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3119 - accuracy: 0.1547 - val_loss: 2.2480 - val_accuracy: 0.1840\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3093 - accuracy: 0.1549 - val_loss: 2.2467 - val_accuracy: 0.1845\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.3089 - accuracy: 0.1556 - val_loss: 2.2461 - val_accuracy: 0.1824\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 9s 11ms/step - loss: 2.2437 - accuracy: 0.1885 - val_loss: 2.2321 - val_accuracy: 0.1960\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 2.2385 - accuracy: 0.1897 - val_loss: 2.2284 - val_accuracy: 0.1960\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 2.2319 - accuracy: 0.1924 - val_loss: 2.2154 - val_accuracy: 0.2296\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 2.1980 - accuracy: 0.2163 - val_loss: 2.1435 - val_accuracy: 0.2510\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 1.9861 - accuracy: 0.3224 - val_loss: 1.8735 - val_accuracy: 0.3800\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 1.6619 - accuracy: 0.4607 - val_loss: 1.5888 - val_accuracy: 0.4890\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 1.4586 - accuracy: 0.5398 - val_loss: 1.4007 - val_accuracy: 0.5719\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 1.3317 - accuracy: 0.5868 - val_loss: 1.3507 - val_accuracy: 0.5919\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 1.2465 - accuracy: 0.6186 - val_loss: 1.2787 - val_accuracy: 0.6194\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 5s 8ms/step - loss: 1.1814 - accuracy: 0.6405 - val_loss: 1.2035 - val_accuracy: 0.6509\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2685 - accuracy: 0.1619 - val_loss: 2.2475 - val_accuracy: 0.1949\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2509 - accuracy: 0.1810 - val_loss: 2.2454 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2496 - accuracy: 0.1846 - val_loss: 2.2441 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2477 - accuracy: 0.1858 - val_loss: 2.2439 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2470 - accuracy: 0.1869 - val_loss: 2.2411 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2458 - accuracy: 0.1888 - val_loss: 2.2399 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2445 - accuracy: 0.1883 - val_loss: 2.2388 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2436 - accuracy: 0.1880 - val_loss: 2.2382 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2443 - accuracy: 0.1880 - val_loss: 2.2373 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2423 - accuracy: 0.1890 - val_loss: 2.2348 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 8s 9ms/step - loss: 2.2698 - accuracy: 0.1715 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2468 - accuracy: 0.1873 - val_loss: 2.2335 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2447 - accuracy: 0.1879 - val_loss: 2.2305 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2422 - accuracy: 0.1884 - val_loss: 2.2299 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2409 - accuracy: 0.1885 - val_loss: 2.2263 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2396 - accuracy: 0.1892 - val_loss: 2.2275 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2372 - accuracy: 0.1890 - val_loss: 2.2230 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2341 - accuracy: 0.1892 - val_loss: 2.2156 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2280 - accuracy: 0.1893 - val_loss: 2.2045 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2151 - accuracy: 0.1893 - val_loss: 2.1838 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2569 - accuracy: 0.1767 - val_loss: 2.2406 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2415 - accuracy: 0.1888 - val_loss: 2.2376 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2390 - accuracy: 0.1893 - val_loss: 2.2362 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2369 - accuracy: 0.1898 - val_loss: 2.2335 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2340 - accuracy: 0.1897 - val_loss: 2.2321 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2308 - accuracy: 0.1898 - val_loss: 2.2286 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2267 - accuracy: 0.1913 - val_loss: 2.2235 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2216 - accuracy: 0.1926 - val_loss: 2.2201 - val_accuracy: 0.1962\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2156 - accuracy: 0.1952 - val_loss: 2.2132 - val_accuracy: 0.1968\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2070 - accuracy: 0.1976 - val_loss: 2.2032 - val_accuracy: 0.2008\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2548 - accuracy: 0.1787 - val_loss: 2.2370 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2444 - accuracy: 0.1884 - val_loss: 2.2355 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2424 - accuracy: 0.1890 - val_loss: 2.2346 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2400 - accuracy: 0.1890 - val_loss: 2.2324 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2396 - accuracy: 0.1893 - val_loss: 2.2324 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2383 - accuracy: 0.1895 - val_loss: 2.2294 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2366 - accuracy: 0.1891 - val_loss: 2.2266 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2351 - accuracy: 0.1896 - val_loss: 2.2268 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2337 - accuracy: 0.1894 - val_loss: 2.2240 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2318 - accuracy: 0.1896 - val_loss: 2.2221 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2524 - accuracy: 0.1781 - val_loss: 2.2368 - val_accuracy: 0.1961\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2424 - accuracy: 0.1890 - val_loss: 2.2361 - val_accuracy: 0.1960\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2392 - accuracy: 0.1893 - val_loss: 2.2325 - val_accuracy: 0.1960\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2361 - accuracy: 0.1898 - val_loss: 2.2287 - val_accuracy: 0.1960\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2333 - accuracy: 0.1903 - val_loss: 2.2274 - val_accuracy: 0.1963\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2302 - accuracy: 0.1903 - val_loss: 2.2234 - val_accuracy: 0.1965\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2272 - accuracy: 0.1906 - val_loss: 2.2221 - val_accuracy: 0.1967\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2242 - accuracy: 0.1910 - val_loss: 2.2201 - val_accuracy: 0.1971\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2206 - accuracy: 0.1921 - val_loss: 2.2161 - val_accuracy: 0.1989\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2162 - accuracy: 0.1937 - val_loss: 2.2138 - val_accuracy: 0.1986\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2643 - accuracy: 0.1660 - val_loss: 2.2368 - val_accuracy: 0.1951\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2481 - accuracy: 0.1848 - val_loss: 2.2316 - val_accuracy: 0.1958\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2447 - accuracy: 0.1873 - val_loss: 2.2283 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2376 - accuracy: 0.1885 - val_loss: 2.2222 - val_accuracy: 0.1958\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2312 - accuracy: 0.1898 - val_loss: 2.2096 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2200 - accuracy: 0.1901 - val_loss: 2.1947 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2018 - accuracy: 0.1941 - val_loss: 2.1679 - val_accuracy: 0.1962\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1748 - accuracy: 0.1988 - val_loss: 2.1333 - val_accuracy: 0.2016\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1383 - accuracy: 0.2099 - val_loss: 2.0775 - val_accuracy: 0.2206\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0914 - accuracy: 0.2369 - val_loss: 2.0267 - val_accuracy: 0.2944\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2594 - accuracy: 0.1706 - val_loss: 2.2364 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2447 - accuracy: 0.1875 - val_loss: 2.2336 - val_accuracy: 0.1960\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2408 - accuracy: 0.1876 - val_loss: 2.2316 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2392 - accuracy: 0.1889 - val_loss: 2.2284 - val_accuracy: 0.1960\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2351 - accuracy: 0.1881 - val_loss: 2.2263 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2320 - accuracy: 0.1899 - val_loss: 2.2233 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2291 - accuracy: 0.1904 - val_loss: 2.2213 - val_accuracy: 0.1960\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2258 - accuracy: 0.1906 - val_loss: 2.2197 - val_accuracy: 0.1960\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2232 - accuracy: 0.1911 - val_loss: 2.2165 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2211 - accuracy: 0.1910 - val_loss: 2.2150 - val_accuracy: 0.1962\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.3050 - accuracy: 0.1529 - val_loss: 2.2433 - val_accuracy: 0.1941\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2793 - accuracy: 0.1689 - val_loss: 2.2385 - val_accuracy: 0.1938\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2730 - accuracy: 0.1727 - val_loss: 2.2354 - val_accuracy: 0.1934\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2663 - accuracy: 0.1773 - val_loss: 2.2324 - val_accuracy: 0.1955\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2596 - accuracy: 0.1760 - val_loss: 2.2296 - val_accuracy: 0.1955\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2582 - accuracy: 0.1798 - val_loss: 2.2290 - val_accuracy: 0.1963\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2549 - accuracy: 0.1810 - val_loss: 2.2276 - val_accuracy: 0.1963\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2513 - accuracy: 0.1827 - val_loss: 2.2256 - val_accuracy: 0.1968\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2504 - accuracy: 0.1838 - val_loss: 2.2240 - val_accuracy: 0.1969\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2478 - accuracy: 0.1850 - val_loss: 2.2224 - val_accuracy: 0.1968\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2639 - accuracy: 0.1696 - val_loss: 2.2477 - val_accuracy: 0.1825\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2534 - accuracy: 0.1786 - val_loss: 2.2435 - val_accuracy: 0.1862\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2483 - accuracy: 0.1844 - val_loss: 2.2402 - val_accuracy: 0.1872\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2443 - accuracy: 0.1875 - val_loss: 2.2372 - val_accuracy: 0.1891\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2409 - accuracy: 0.1901 - val_loss: 2.2365 - val_accuracy: 0.1922\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2377 - accuracy: 0.1919 - val_loss: 2.2354 - val_accuracy: 0.1934\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2348 - accuracy: 0.1946 - val_loss: 2.2358 - val_accuracy: 0.1953\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2323 - accuracy: 0.1968 - val_loss: 2.2322 - val_accuracy: 0.1956\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2297 - accuracy: 0.1982 - val_loss: 2.2321 - val_accuracy: 0.1972\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 3ms/step - loss: 2.2273 - accuracy: 0.2010 - val_loss: 2.2302 - val_accuracy: 0.1983\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2611 - accuracy: 0.1767 - val_loss: 2.2370 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2516 - accuracy: 0.1841 - val_loss: 2.2342 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2485 - accuracy: 0.1868 - val_loss: 2.2314 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2465 - accuracy: 0.1868 - val_loss: 2.2288 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2447 - accuracy: 0.1877 - val_loss: 2.2274 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2424 - accuracy: 0.1876 - val_loss: 2.2247 - val_accuracy: 0.1958\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2415 - accuracy: 0.1876 - val_loss: 2.2226 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2397 - accuracy: 0.1878 - val_loss: 2.2212 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2368 - accuracy: 0.1882 - val_loss: 2.2170 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2351 - accuracy: 0.1885 - val_loss: 2.2154 - val_accuracy: 0.1958\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2482 - accuracy: 0.1877 - val_loss: 2.2389 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2422 - accuracy: 0.1898 - val_loss: 2.2349 - val_accuracy: 0.1960\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2387 - accuracy: 0.1901 - val_loss: 2.2326 - val_accuracy: 0.1960\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2351 - accuracy: 0.1904 - val_loss: 2.2295 - val_accuracy: 0.1961\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2310 - accuracy: 0.1910 - val_loss: 2.2253 - val_accuracy: 0.1960\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2265 - accuracy: 0.1914 - val_loss: 2.2233 - val_accuracy: 0.1964\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2210 - accuracy: 0.1924 - val_loss: 2.2184 - val_accuracy: 0.1968\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2150 - accuracy: 0.1950 - val_loss: 2.2128 - val_accuracy: 0.1963\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2082 - accuracy: 0.1974 - val_loss: 2.2065 - val_accuracy: 0.1984\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2004 - accuracy: 0.2004 - val_loss: 2.2006 - val_accuracy: 0.2097\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2686 - accuracy: 0.1680 - val_loss: 2.2374 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2511 - accuracy: 0.1828 - val_loss: 2.2338 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2482 - accuracy: 0.1856 - val_loss: 2.2328 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2459 - accuracy: 0.1867 - val_loss: 2.2336 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2440 - accuracy: 0.1867 - val_loss: 2.2291 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2425 - accuracy: 0.1880 - val_loss: 2.2275 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2409 - accuracy: 0.1881 - val_loss: 2.2247 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2379 - accuracy: 0.1887 - val_loss: 2.2255 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2340 - accuracy: 0.1887 - val_loss: 2.2141 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2263 - accuracy: 0.1891 - val_loss: 2.1984 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2616 - accuracy: 0.1674 - val_loss: 2.2368 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2501 - accuracy: 0.1833 - val_loss: 2.2331 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2461 - accuracy: 0.1857 - val_loss: 2.2284 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2383 - accuracy: 0.1899 - val_loss: 2.2130 - val_accuracy: 0.1990\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2256 - accuracy: 0.1974 - val_loss: 2.1990 - val_accuracy: 0.2220\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2059 - accuracy: 0.2099 - val_loss: 2.1634 - val_accuracy: 0.2154\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1676 - accuracy: 0.2357 - val_loss: 2.1041 - val_accuracy: 0.2600\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1031 - accuracy: 0.2700 - val_loss: 2.0121 - val_accuracy: 0.3334\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0177 - accuracy: 0.3099 - val_loss: 1.9091 - val_accuracy: 0.3728\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9265 - accuracy: 0.3462 - val_loss: 1.8102 - val_accuracy: 0.4201\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2479 - accuracy: 0.1875 - val_loss: 2.2323 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2415 - accuracy: 0.1894 - val_loss: 2.2267 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2303 - accuracy: 0.1944 - val_loss: 2.2121 - val_accuracy: 0.2029\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2079 - accuracy: 0.2061 - val_loss: 2.1821 - val_accuracy: 0.2016\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1648 - accuracy: 0.2260 - val_loss: 2.1196 - val_accuracy: 0.2319\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0905 - accuracy: 0.2692 - val_loss: 2.0313 - val_accuracy: 0.3291\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9896 - accuracy: 0.3221 - val_loss: 1.9006 - val_accuracy: 0.3884\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.8795 - accuracy: 0.3726 - val_loss: 1.7815 - val_accuracy: 0.4300\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7804 - accuracy: 0.4128 - val_loss: 1.6826 - val_accuracy: 0.4656\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6921 - accuracy: 0.4487 - val_loss: 1.6139 - val_accuracy: 0.5053\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2743 - accuracy: 0.1679 - val_loss: 2.2410 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2543 - accuracy: 0.1822 - val_loss: 2.2362 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2514 - accuracy: 0.1850 - val_loss: 2.2340 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2497 - accuracy: 0.1839 - val_loss: 2.2317 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2482 - accuracy: 0.1854 - val_loss: 2.2315 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2463 - accuracy: 0.1863 - val_loss: 2.2304 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2456 - accuracy: 0.1869 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2444 - accuracy: 0.1855 - val_loss: 2.2275 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2427 - accuracy: 0.1874 - val_loss: 2.2264 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2418 - accuracy: 0.1872 - val_loss: 2.2247 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2359 - accuracy: 0.1912 - val_loss: 2.2064 - val_accuracy: 0.2032\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1778 - accuracy: 0.2191 - val_loss: 2.1239 - val_accuracy: 0.2722\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0765 - accuracy: 0.2901 - val_loss: 2.0167 - val_accuracy: 0.3240\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9371 - accuracy: 0.3755 - val_loss: 1.8802 - val_accuracy: 0.3839\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7853 - accuracy: 0.4437 - val_loss: 1.7279 - val_accuracy: 0.4731\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6436 - accuracy: 0.4971 - val_loss: 1.6032 - val_accuracy: 0.5240\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.5277 - accuracy: 0.5423 - val_loss: 1.4913 - val_accuracy: 0.5496\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.4316 - accuracy: 0.5748 - val_loss: 1.4192 - val_accuracy: 0.5867\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.3539 - accuracy: 0.6010 - val_loss: 1.3825 - val_accuracy: 0.5665\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.2918 - accuracy: 0.6208 - val_loss: 1.3753 - val_accuracy: 0.5853\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2635 - accuracy: 0.1829 - val_loss: 2.2254 - val_accuracy: 0.2073\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2307 - accuracy: 0.1990 - val_loss: 2.2086 - val_accuracy: 0.2131\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2157 - accuracy: 0.2103 - val_loss: 2.1928 - val_accuracy: 0.2321\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1974 - accuracy: 0.2208 - val_loss: 2.1715 - val_accuracy: 0.2425\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1762 - accuracy: 0.2312 - val_loss: 2.1494 - val_accuracy: 0.2515\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1537 - accuracy: 0.2458 - val_loss: 2.1259 - val_accuracy: 0.2593\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1301 - accuracy: 0.2608 - val_loss: 2.1032 - val_accuracy: 0.2629\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1055 - accuracy: 0.2757 - val_loss: 2.0770 - val_accuracy: 0.2910\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0802 - accuracy: 0.2902 - val_loss: 2.0538 - val_accuracy: 0.3018\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0563 - accuracy: 0.3044 - val_loss: 2.0272 - val_accuracy: 0.3318\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2495 - accuracy: 0.1846 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2436 - accuracy: 0.1882 - val_loss: 2.2326 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2406 - accuracy: 0.1875 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2367 - accuracy: 0.1889 - val_loss: 2.2255 - val_accuracy: 0.1961\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2330 - accuracy: 0.1882 - val_loss: 2.2200 - val_accuracy: 0.1970\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2291 - accuracy: 0.1879 - val_loss: 2.2161 - val_accuracy: 0.1963\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2245 - accuracy: 0.1902 - val_loss: 2.2108 - val_accuracy: 0.2037\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2194 - accuracy: 0.1927 - val_loss: 2.2042 - val_accuracy: 0.2075\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2138 - accuracy: 0.1939 - val_loss: 2.1973 - val_accuracy: 0.2107\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2061 - accuracy: 0.1971 - val_loss: 2.1867 - val_accuracy: 0.2240\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2671 - accuracy: 0.1771 - val_loss: 2.2390 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2544 - accuracy: 0.1829 - val_loss: 2.2339 - val_accuracy: 0.1961\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2481 - accuracy: 0.1862 - val_loss: 2.2268 - val_accuracy: 0.1967\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2411 - accuracy: 0.1887 - val_loss: 2.2156 - val_accuracy: 0.1964\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2308 - accuracy: 0.1905 - val_loss: 2.1986 - val_accuracy: 0.1969\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2141 - accuracy: 0.1965 - val_loss: 2.1741 - val_accuracy: 0.2067\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1927 - accuracy: 0.2022 - val_loss: 2.1458 - val_accuracy: 0.2150\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1653 - accuracy: 0.2138 - val_loss: 2.1106 - val_accuracy: 0.2306\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1346 - accuracy: 0.2266 - val_loss: 2.0757 - val_accuracy: 0.2569\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1084 - accuracy: 0.2396 - val_loss: 2.0501 - val_accuracy: 0.2635\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.3081 - accuracy: 0.1516 - val_loss: 2.2471 - val_accuracy: 0.1927\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2764 - accuracy: 0.1673 - val_loss: 2.2391 - val_accuracy: 0.1939\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2666 - accuracy: 0.1729 - val_loss: 2.2393 - val_accuracy: 0.1960\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2602 - accuracy: 0.1811 - val_loss: 2.2374 - val_accuracy: 0.1963\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2564 - accuracy: 0.1803 - val_loss: 2.2342 - val_accuracy: 0.1968\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2539 - accuracy: 0.1824 - val_loss: 2.2316 - val_accuracy: 0.1972\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2512 - accuracy: 0.1849 - val_loss: 2.2290 - val_accuracy: 0.1980\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2497 - accuracy: 0.1867 - val_loss: 2.2275 - val_accuracy: 0.1988\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2474 - accuracy: 0.1884 - val_loss: 2.2248 - val_accuracy: 0.1986\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2455 - accuracy: 0.1861 - val_loss: 2.2228 - val_accuracy: 0.1993\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2548 - accuracy: 0.1857 - val_loss: 2.2356 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2444 - accuracy: 0.1890 - val_loss: 2.2269 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2368 - accuracy: 0.1932 - val_loss: 2.2109 - val_accuracy: 0.2020\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2179 - accuracy: 0.2044 - val_loss: 2.1717 - val_accuracy: 0.2332\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1608 - accuracy: 0.2384 - val_loss: 2.0906 - val_accuracy: 0.2529\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.0464 - accuracy: 0.2953 - val_loss: 1.8984 - val_accuracy: 0.3798\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.9198 - accuracy: 0.3502 - val_loss: 1.7673 - val_accuracy: 0.4406\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.8091 - accuracy: 0.3963 - val_loss: 1.6575 - val_accuracy: 0.4723\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.7042 - accuracy: 0.4368 - val_loss: 1.5459 - val_accuracy: 0.5174\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.6178 - accuracy: 0.4689 - val_loss: 1.4598 - val_accuracy: 0.5552\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2684 - accuracy: 0.1758 - val_loss: 2.2401 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2486 - accuracy: 0.1874 - val_loss: 2.2390 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2469 - accuracy: 0.1878 - val_loss: 2.2373 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2454 - accuracy: 0.1878 - val_loss: 2.2362 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2437 - accuracy: 0.1884 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2429 - accuracy: 0.1887 - val_loss: 2.2329 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2419 - accuracy: 0.1889 - val_loss: 2.2317 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2409 - accuracy: 0.1890 - val_loss: 2.2311 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2391 - accuracy: 0.1892 - val_loss: 2.2267 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2382 - accuracy: 0.1892 - val_loss: 2.2255 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2640 - accuracy: 0.1566 - val_loss: 2.2414 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2487 - accuracy: 0.1870 - val_loss: 2.2381 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2451 - accuracy: 0.1881 - val_loss: 2.2334 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2432 - accuracy: 0.1886 - val_loss: 2.2332 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2411 - accuracy: 0.1886 - val_loss: 2.2309 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2385 - accuracy: 0.1891 - val_loss: 2.2306 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2373 - accuracy: 0.1892 - val_loss: 2.2261 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2337 - accuracy: 0.1892 - val_loss: 2.2210 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2308 - accuracy: 0.1891 - val_loss: 2.2179 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2247 - accuracy: 0.1895 - val_loss: 2.2072 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2493 - accuracy: 0.1819 - val_loss: 2.2465 - val_accuracy: 0.1957\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2418 - accuracy: 0.1891 - val_loss: 2.2448 - val_accuracy: 0.1958\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2398 - accuracy: 0.1894 - val_loss: 2.2453 - val_accuracy: 0.1958\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2378 - accuracy: 0.1891 - val_loss: 2.2418 - val_accuracy: 0.1958\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2363 - accuracy: 0.1892 - val_loss: 2.2405 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2338 - accuracy: 0.1895 - val_loss: 2.2408 - val_accuracy: 0.1958\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2306 - accuracy: 0.1897 - val_loss: 2.2353 - val_accuracy: 0.1965\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2278 - accuracy: 0.1905 - val_loss: 2.2330 - val_accuracy: 0.1968\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2241 - accuracy: 0.1916 - val_loss: 2.2321 - val_accuracy: 0.2023\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2198 - accuracy: 0.1934 - val_loss: 2.2271 - val_accuracy: 0.2026\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2637 - accuracy: 0.1761 - val_loss: 2.2430 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2511 - accuracy: 0.1847 - val_loss: 2.2408 - val_accuracy: 0.1958\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2472 - accuracy: 0.1854 - val_loss: 2.2381 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2450 - accuracy: 0.1875 - val_loss: 2.2364 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2427 - accuracy: 0.1877 - val_loss: 2.2363 - val_accuracy: 0.1960\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2411 - accuracy: 0.1894 - val_loss: 2.2345 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2391 - accuracy: 0.1892 - val_loss: 2.2334 - val_accuracy: 0.1961\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2382 - accuracy: 0.1892 - val_loss: 2.2314 - val_accuracy: 0.1960\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2365 - accuracy: 0.1890 - val_loss: 2.2297 - val_accuracy: 0.1963\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2351 - accuracy: 0.1893 - val_loss: 2.2309 - val_accuracy: 0.1963\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 8s 11ms/step - loss: 2.2445 - accuracy: 0.1883 - val_loss: 2.2321 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2403 - accuracy: 0.1893 - val_loss: 2.2296 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2382 - accuracy: 0.1893 - val_loss: 2.2262 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2358 - accuracy: 0.1897 - val_loss: 2.2231 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2330 - accuracy: 0.1896 - val_loss: 2.2194 - val_accuracy: 0.1960\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2280 - accuracy: 0.1923 - val_loss: 2.2136 - val_accuracy: 0.2072\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2204 - accuracy: 0.1962 - val_loss: 2.2028 - val_accuracy: 0.2066\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.2021 - accuracy: 0.2099 - val_loss: 2.1955 - val_accuracy: 0.2112\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.1542 - accuracy: 0.2396 - val_loss: 2.1177 - val_accuracy: 0.2374\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 5s 9ms/step - loss: 2.0119 - accuracy: 0.3166 - val_loss: 1.8665 - val_accuracy: 0.3689\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2488 - accuracy: 0.1823 - val_loss: 2.2045 - val_accuracy: 0.2198\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2024 - accuracy: 0.2102 - val_loss: 2.1687 - val_accuracy: 0.2472\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1690 - accuracy: 0.2286 - val_loss: 2.1372 - val_accuracy: 0.2359\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1333 - accuracy: 0.2513 - val_loss: 2.1003 - val_accuracy: 0.2916\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0981 - accuracy: 0.2764 - val_loss: 2.0659 - val_accuracy: 0.2972\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0605 - accuracy: 0.2994 - val_loss: 2.0287 - val_accuracy: 0.3169\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0251 - accuracy: 0.3208 - val_loss: 1.9921 - val_accuracy: 0.3476\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9874 - accuracy: 0.3446 - val_loss: 1.9598 - val_accuracy: 0.3559\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9517 - accuracy: 0.3653 - val_loss: 1.9271 - val_accuracy: 0.4070\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9170 - accuracy: 0.3835 - val_loss: 1.8860 - val_accuracy: 0.4060\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2638 - accuracy: 0.1718 - val_loss: 2.2322 - val_accuracy: 0.1969\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2456 - accuracy: 0.1868 - val_loss: 2.2208 - val_accuracy: 0.1990\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2359 - accuracy: 0.1936 - val_loss: 2.2105 - val_accuracy: 0.2012\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2230 - accuracy: 0.1995 - val_loss: 2.1963 - val_accuracy: 0.2074\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2047 - accuracy: 0.2091 - val_loss: 2.1728 - val_accuracy: 0.2115\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1841 - accuracy: 0.2189 - val_loss: 2.1467 - val_accuracy: 0.2303\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1577 - accuracy: 0.2339 - val_loss: 2.1161 - val_accuracy: 0.2560\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1262 - accuracy: 0.2497 - val_loss: 2.0764 - val_accuracy: 0.2724\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0863 - accuracy: 0.2668 - val_loss: 2.0301 - val_accuracy: 0.3044\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0473 - accuracy: 0.2872 - val_loss: 1.9832 - val_accuracy: 0.3184\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2396 - accuracy: 0.1891 - val_loss: 2.2193 - val_accuracy: 0.2018\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2102 - accuracy: 0.2089 - val_loss: 2.1816 - val_accuracy: 0.2160\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.1627 - accuracy: 0.2381 - val_loss: 2.1326 - val_accuracy: 0.2525\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.0972 - accuracy: 0.2753 - val_loss: 2.0548 - val_accuracy: 0.3125\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.0117 - accuracy: 0.3195 - val_loss: 1.9653 - val_accuracy: 0.3315\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.9123 - accuracy: 0.3697 - val_loss: 1.8648 - val_accuracy: 0.3841\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.8098 - accuracy: 0.4202 - val_loss: 1.7691 - val_accuracy: 0.4416\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.7081 - accuracy: 0.4698 - val_loss: 1.6892 - val_accuracy: 0.4506\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.6153 - accuracy: 0.5095 - val_loss: 1.6115 - val_accuracy: 0.5275\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.5322 - accuracy: 0.5367 - val_loss: 1.5360 - val_accuracy: 0.5327\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2512 - accuracy: 0.1802 - val_loss: 2.2309 - val_accuracy: 0.2158\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2396 - accuracy: 0.1885 - val_loss: 2.2142 - val_accuracy: 0.2044\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2214 - accuracy: 0.2020 - val_loss: 2.1831 - val_accuracy: 0.2349\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1883 - accuracy: 0.2284 - val_loss: 2.1298 - val_accuracy: 0.2361\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1280 - accuracy: 0.2744 - val_loss: 2.0340 - val_accuracy: 0.3466\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0284 - accuracy: 0.3324 - val_loss: 1.9113 - val_accuracy: 0.4259\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9001 - accuracy: 0.3829 - val_loss: 1.7624 - val_accuracy: 0.4536\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7728 - accuracy: 0.4242 - val_loss: 1.6383 - val_accuracy: 0.4890\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6659 - accuracy: 0.4565 - val_loss: 1.5758 - val_accuracy: 0.5024\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.5816 - accuracy: 0.4817 - val_loss: 1.4849 - val_accuracy: 0.5463\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2508 - accuracy: 0.1830 - val_loss: 2.2363 - val_accuracy: 0.1960\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2412 - accuracy: 0.1895 - val_loss: 2.2335 - val_accuracy: 0.1964\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2393 - accuracy: 0.1902 - val_loss: 2.2310 - val_accuracy: 0.1998\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2360 - accuracy: 0.1909 - val_loss: 2.2277 - val_accuracy: 0.1967\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2320 - accuracy: 0.1925 - val_loss: 2.2235 - val_accuracy: 0.1996\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2284 - accuracy: 0.1936 - val_loss: 2.2204 - val_accuracy: 0.2003\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2235 - accuracy: 0.1952 - val_loss: 2.2151 - val_accuracy: 0.2033\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2187 - accuracy: 0.1974 - val_loss: 2.2106 - val_accuracy: 0.2011\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2128 - accuracy: 0.2009 - val_loss: 2.2049 - val_accuracy: 0.2044\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2070 - accuracy: 0.2013 - val_loss: 2.2006 - val_accuracy: 0.2102\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2477 - accuracy: 0.1846 - val_loss: 2.2297 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2293 - accuracy: 0.1952 - val_loss: 2.2068 - val_accuracy: 0.2102\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1946 - accuracy: 0.2204 - val_loss: 2.1573 - val_accuracy: 0.2445\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1415 - accuracy: 0.2554 - val_loss: 2.0943 - val_accuracy: 0.2954\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0678 - accuracy: 0.2903 - val_loss: 2.0117 - val_accuracy: 0.3144\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9787 - accuracy: 0.3282 - val_loss: 1.9037 - val_accuracy: 0.3740\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.8842 - accuracy: 0.3666 - val_loss: 1.8027 - val_accuracy: 0.3998\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7926 - accuracy: 0.4070 - val_loss: 1.7240 - val_accuracy: 0.4705\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7103 - accuracy: 0.4388 - val_loss: 1.6277 - val_accuracy: 0.5044\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6381 - accuracy: 0.4659 - val_loss: 1.5627 - val_accuracy: 0.5161\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2692 - accuracy: 0.1668 - val_loss: 2.2377 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2455 - accuracy: 0.1888 - val_loss: 2.2345 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2434 - accuracy: 0.1893 - val_loss: 2.2331 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2417 - accuracy: 0.1892 - val_loss: 2.2313 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2404 - accuracy: 0.1890 - val_loss: 2.2305 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2396 - accuracy: 0.1890 - val_loss: 2.2292 - val_accuracy: 0.1958\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2389 - accuracy: 0.1891 - val_loss: 2.2277 - val_accuracy: 0.1958\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2372 - accuracy: 0.1892 - val_loss: 2.2263 - val_accuracy: 0.1958\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2368 - accuracy: 0.1890 - val_loss: 2.2262 - val_accuracy: 0.1958\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2353 - accuracy: 0.1893 - val_loss: 2.2248 - val_accuracy: 0.1958\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2654 - accuracy: 0.1637 - val_loss: 2.2408 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2493 - accuracy: 0.1846 - val_loss: 2.2386 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2470 - accuracy: 0.1864 - val_loss: 2.2361 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2451 - accuracy: 0.1868 - val_loss: 2.2337 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2434 - accuracy: 0.1880 - val_loss: 2.2325 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2416 - accuracy: 0.1882 - val_loss: 2.2302 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2399 - accuracy: 0.1887 - val_loss: 2.2307 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2381 - accuracy: 0.1883 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2368 - accuracy: 0.1886 - val_loss: 2.2249 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2346 - accuracy: 0.1883 - val_loss: 2.2217 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2516 - accuracy: 0.1848 - val_loss: 2.2224 - val_accuracy: 0.1985\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2241 - accuracy: 0.1948 - val_loss: 2.1964 - val_accuracy: 0.2057\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1986 - accuracy: 0.2041 - val_loss: 2.1622 - val_accuracy: 0.2331\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1636 - accuracy: 0.2189 - val_loss: 2.1274 - val_accuracy: 0.2654\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1220 - accuracy: 0.2433 - val_loss: 2.0760 - val_accuracy: 0.2819\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0747 - accuracy: 0.2707 - val_loss: 2.0256 - val_accuracy: 0.3320\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0246 - accuracy: 0.3024 - val_loss: 1.9667 - val_accuracy: 0.3493\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9727 - accuracy: 0.3313 - val_loss: 1.9139 - val_accuracy: 0.3599\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9224 - accuracy: 0.3563 - val_loss: 1.8618 - val_accuracy: 0.3728\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.8687 - accuracy: 0.3838 - val_loss: 1.8087 - val_accuracy: 0.4084\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2442 - accuracy: 0.1856 - val_loss: 2.2199 - val_accuracy: 0.1974\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2121 - accuracy: 0.2009 - val_loss: 2.1731 - val_accuracy: 0.2214\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1488 - accuracy: 0.2353 - val_loss: 2.0862 - val_accuracy: 0.2727\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0539 - accuracy: 0.2920 - val_loss: 1.9793 - val_accuracy: 0.2960\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9329 - accuracy: 0.3573 - val_loss: 1.8666 - val_accuracy: 0.3926\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.8099 - accuracy: 0.4070 - val_loss: 1.7257 - val_accuracy: 0.4485\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7014 - accuracy: 0.4459 - val_loss: 1.6645 - val_accuracy: 0.4395\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6102 - accuracy: 0.4801 - val_loss: 1.5371 - val_accuracy: 0.5356\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.5314 - accuracy: 0.5082 - val_loss: 1.4806 - val_accuracy: 0.5361\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.4649 - accuracy: 0.5353 - val_loss: 1.4257 - val_accuracy: 0.5683\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2541 - accuracy: 0.1838 - val_loss: 2.2355 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2419 - accuracy: 0.1906 - val_loss: 2.2238 - val_accuracy: 0.1973\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2311 - accuracy: 0.1938 - val_loss: 2.2104 - val_accuracy: 0.2031\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2078 - accuracy: 0.2068 - val_loss: 2.1764 - val_accuracy: 0.2089\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1628 - accuracy: 0.2387 - val_loss: 2.1101 - val_accuracy: 0.2422\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.0859 - accuracy: 0.2869 - val_loss: 2.0092 - val_accuracy: 0.3467\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.9914 - accuracy: 0.3334 - val_loss: 1.9042 - val_accuracy: 0.3750\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.8852 - accuracy: 0.3783 - val_loss: 1.7906 - val_accuracy: 0.4145\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.7824 - accuracy: 0.4180 - val_loss: 1.6821 - val_accuracy: 0.4702\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.6841 - accuracy: 0.4538 - val_loss: 1.5874 - val_accuracy: 0.4940\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2553 - accuracy: 0.1768 - val_loss: 2.2436 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2419 - accuracy: 0.1891 - val_loss: 2.2413 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2397 - accuracy: 0.1893 - val_loss: 2.2392 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2380 - accuracy: 0.1894 - val_loss: 2.2358 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2362 - accuracy: 0.1896 - val_loss: 2.2327 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2341 - accuracy: 0.1899 - val_loss: 2.2335 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2312 - accuracy: 0.1902 - val_loss: 2.2278 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2275 - accuracy: 0.1912 - val_loss: 2.2234 - val_accuracy: 0.1960\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2225 - accuracy: 0.1931 - val_loss: 2.2189 - val_accuracy: 0.1971\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2136 - accuracy: 0.1974 - val_loss: 2.2116 - val_accuracy: 0.2128\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2788 - accuracy: 0.1380 - val_loss: 2.2380 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2499 - accuracy: 0.1814 - val_loss: 2.2320 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2460 - accuracy: 0.1858 - val_loss: 2.2320 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2413 - accuracy: 0.1877 - val_loss: 2.2264 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2363 - accuracy: 0.1888 - val_loss: 2.2173 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2281 - accuracy: 0.1892 - val_loss: 2.2057 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2097 - accuracy: 0.1895 - val_loss: 2.1736 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1753 - accuracy: 0.1901 - val_loss: 2.1325 - val_accuracy: 0.2002\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1317 - accuracy: 0.2000 - val_loss: 2.0841 - val_accuracy: 0.2269\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0935 - accuracy: 0.2218 - val_loss: 2.0410 - val_accuracy: 0.2362\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2683 - accuracy: 0.1774 - val_loss: 2.2562 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2525 - accuracy: 0.1844 - val_loss: 2.2528 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2480 - accuracy: 0.1857 - val_loss: 2.2504 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2457 - accuracy: 0.1871 - val_loss: 2.2486 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2446 - accuracy: 0.1885 - val_loss: 2.2462 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2429 - accuracy: 0.1884 - val_loss: 2.2457 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2416 - accuracy: 0.1901 - val_loss: 2.2458 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2412 - accuracy: 0.1887 - val_loss: 2.2434 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2389 - accuracy: 0.1894 - val_loss: 2.2439 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2384 - accuracy: 0.1896 - val_loss: 2.2402 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2889 - accuracy: 0.1545 - val_loss: 2.2672 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2673 - accuracy: 0.1833 - val_loss: 2.2578 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2598 - accuracy: 0.1850 - val_loss: 2.2521 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2552 - accuracy: 0.1852 - val_loss: 2.2483 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2536 - accuracy: 0.1844 - val_loss: 2.2454 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2517 - accuracy: 0.1836 - val_loss: 2.2433 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2506 - accuracy: 0.1831 - val_loss: 2.2422 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2487 - accuracy: 0.1838 - val_loss: 2.2413 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2483 - accuracy: 0.1844 - val_loss: 2.2406 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2477 - accuracy: 0.1845 - val_loss: 2.2399 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 7s 8ms/step - loss: 2.2827 - accuracy: 0.1661 - val_loss: 2.2417 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2502 - accuracy: 0.1848 - val_loss: 2.2336 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2458 - accuracy: 0.1874 - val_loss: 2.2315 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2440 - accuracy: 0.1878 - val_loss: 2.2309 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2428 - accuracy: 0.1877 - val_loss: 2.2297 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2417 - accuracy: 0.1884 - val_loss: 2.2277 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2401 - accuracy: 0.1889 - val_loss: 2.2268 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2394 - accuracy: 0.1891 - val_loss: 2.2270 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2384 - accuracy: 0.1892 - val_loss: 2.2237 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2365 - accuracy: 0.1893 - val_loss: 2.2225 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2581 - accuracy: 0.1830 - val_loss: 2.2368 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2451 - accuracy: 0.1874 - val_loss: 2.2329 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2401 - accuracy: 0.1895 - val_loss: 2.2258 - val_accuracy: 0.1958\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2343 - accuracy: 0.1896 - val_loss: 2.2233 - val_accuracy: 0.1968\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2271 - accuracy: 0.1914 - val_loss: 2.2141 - val_accuracy: 0.1968\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2165 - accuracy: 0.1939 - val_loss: 2.2025 - val_accuracy: 0.2021\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2008 - accuracy: 0.2001 - val_loss: 2.1851 - val_accuracy: 0.2125\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1819 - accuracy: 0.2087 - val_loss: 2.1604 - val_accuracy: 0.2084\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1539 - accuracy: 0.2214 - val_loss: 2.1369 - val_accuracy: 0.2491\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1183 - accuracy: 0.2377 - val_loss: 2.0911 - val_accuracy: 0.2477\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2685 - accuracy: 0.1560 - val_loss: 2.2503 - val_accuracy: 0.1951\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2459 - accuracy: 0.1857 - val_loss: 2.2433 - val_accuracy: 0.1953\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2453 - accuracy: 0.1882 - val_loss: 2.2430 - val_accuracy: 0.1956\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2444 - accuracy: 0.1878 - val_loss: 2.2423 - val_accuracy: 0.1957\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2447 - accuracy: 0.1877 - val_loss: 2.2409 - val_accuracy: 0.1958\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2437 - accuracy: 0.1889 - val_loss: 2.2409 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2431 - accuracy: 0.1878 - val_loss: 2.2404 - val_accuracy: 0.1958\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2432 - accuracy: 0.1885 - val_loss: 2.2393 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2428 - accuracy: 0.1887 - val_loss: 2.2394 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2422 - accuracy: 0.1885 - val_loss: 2.2386 - val_accuracy: 0.1959\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2862 - accuracy: 0.1239 - val_loss: 2.2565 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2559 - accuracy: 0.1838 - val_loss: 2.2373 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2491 - accuracy: 0.1884 - val_loss: 2.2345 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2472 - accuracy: 0.1887 - val_loss: 2.2331 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2457 - accuracy: 0.1888 - val_loss: 2.2320 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2442 - accuracy: 0.1888 - val_loss: 2.2310 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2435 - accuracy: 0.1890 - val_loss: 2.2300 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2420 - accuracy: 0.1893 - val_loss: 2.2289 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2412 - accuracy: 0.1892 - val_loss: 2.2280 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2410 - accuracy: 0.1891 - val_loss: 2.2278 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2378 - accuracy: 0.1887 - val_loss: 2.2116 - val_accuracy: 0.2107\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1992 - accuracy: 0.2105 - val_loss: 2.1608 - val_accuracy: 0.3011\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1319 - accuracy: 0.2557 - val_loss: 2.0769 - val_accuracy: 0.2919\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0395 - accuracy: 0.3117 - val_loss: 1.9756 - val_accuracy: 0.3267\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9275 - accuracy: 0.3680 - val_loss: 1.8695 - val_accuracy: 0.4125\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.8109 - accuracy: 0.4197 - val_loss: 1.7515 - val_accuracy: 0.4423\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.7023 - accuracy: 0.4658 - val_loss: 1.6696 - val_accuracy: 0.4483\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.6047 - accuracy: 0.5065 - val_loss: 1.5741 - val_accuracy: 0.4909\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.5211 - accuracy: 0.5402 - val_loss: 1.5039 - val_accuracy: 0.5559\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.4464 - accuracy: 0.5658 - val_loss: 1.4497 - val_accuracy: 0.5748\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2538 - accuracy: 0.1814 - val_loss: 2.2624 - val_accuracy: 0.1954\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2455 - accuracy: 0.1874 - val_loss: 2.2606 - val_accuracy: 0.1955\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2440 - accuracy: 0.1877 - val_loss: 2.2586 - val_accuracy: 0.1955\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2430 - accuracy: 0.1882 - val_loss: 2.2567 - val_accuracy: 0.1956\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2426 - accuracy: 0.1890 - val_loss: 2.2563 - val_accuracy: 0.1957\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2416 - accuracy: 0.1886 - val_loss: 2.2548 - val_accuracy: 0.1956\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2411 - accuracy: 0.1888 - val_loss: 2.2531 - val_accuracy: 0.1957\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2408 - accuracy: 0.1890 - val_loss: 2.2512 - val_accuracy: 0.1958\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2399 - accuracy: 0.1892 - val_loss: 2.2495 - val_accuracy: 0.1958\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2393 - accuracy: 0.1892 - val_loss: 2.2489 - val_accuracy: 0.1958\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2467 - accuracy: 0.1874 - val_loss: 2.2309 - val_accuracy: 0.1960\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2325 - accuracy: 0.1949 - val_loss: 2.2131 - val_accuracy: 0.1961\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2007 - accuracy: 0.2132 - val_loss: 2.1680 - val_accuracy: 0.2287\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1448 - accuracy: 0.2352 - val_loss: 2.1024 - val_accuracy: 0.2656\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0638 - accuracy: 0.2780 - val_loss: 2.0066 - val_accuracy: 0.3313\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.9648 - accuracy: 0.3327 - val_loss: 1.9046 - val_accuracy: 0.3986\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.8638 - accuracy: 0.3795 - val_loss: 1.7974 - val_accuracy: 0.3886\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7650 - accuracy: 0.4205 - val_loss: 1.7132 - val_accuracy: 0.4321\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6796 - accuracy: 0.4504 - val_loss: 1.6360 - val_accuracy: 0.4906\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.6037 - accuracy: 0.4790 - val_loss: 1.5567 - val_accuracy: 0.5132\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2434 - accuracy: 0.1888 - val_loss: 2.2339 - val_accuracy: 0.1965\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2326 - accuracy: 0.1930 - val_loss: 2.2302 - val_accuracy: 0.1976\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2232 - accuracy: 0.1976 - val_loss: 2.2235 - val_accuracy: 0.1973\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2143 - accuracy: 0.2027 - val_loss: 2.2193 - val_accuracy: 0.2120\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2051 - accuracy: 0.2082 - val_loss: 2.2150 - val_accuracy: 0.2204\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1968 - accuracy: 0.2146 - val_loss: 2.2144 - val_accuracy: 0.2231\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1883 - accuracy: 0.2195 - val_loss: 2.2056 - val_accuracy: 0.2159\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1803 - accuracy: 0.2256 - val_loss: 2.2018 - val_accuracy: 0.2159\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1722 - accuracy: 0.2307 - val_loss: 2.1993 - val_accuracy: 0.2370\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1638 - accuracy: 0.2363 - val_loss: 2.1959 - val_accuracy: 0.2202\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2864 - accuracy: 0.1593 - val_loss: 2.2438 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2535 - accuracy: 0.1878 - val_loss: 2.2336 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2479 - accuracy: 0.1877 - val_loss: 2.2283 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2416 - accuracy: 0.1892 - val_loss: 2.2222 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2353 - accuracy: 0.1893 - val_loss: 2.2144 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2262 - accuracy: 0.1899 - val_loss: 2.1982 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2093 - accuracy: 0.1900 - val_loss: 2.1719 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1821 - accuracy: 0.1919 - val_loss: 2.1319 - val_accuracy: 0.1998\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1432 - accuracy: 0.2035 - val_loss: 2.0776 - val_accuracy: 0.2294\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0997 - accuracy: 0.2321 - val_loss: 2.0298 - val_accuracy: 0.2934\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2554 - accuracy: 0.1820 - val_loss: 2.2350 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2464 - accuracy: 0.1854 - val_loss: 2.2327 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2431 - accuracy: 0.1880 - val_loss: 2.2300 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2416 - accuracy: 0.1871 - val_loss: 2.2275 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2397 - accuracy: 0.1886 - val_loss: 2.2238 - val_accuracy: 0.1958\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2362 - accuracy: 0.1889 - val_loss: 2.2236 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2340 - accuracy: 0.1894 - val_loss: 2.2184 - val_accuracy: 0.1990\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2306 - accuracy: 0.1896 - val_loss: 2.2142 - val_accuracy: 0.2011\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2262 - accuracy: 0.1909 - val_loss: 2.2077 - val_accuracy: 0.2041\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2186 - accuracy: 0.1938 - val_loss: 2.1944 - val_accuracy: 0.2079\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2461 - accuracy: 0.1875 - val_loss: 2.2355 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2403 - accuracy: 0.1894 - val_loss: 2.2287 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2348 - accuracy: 0.1914 - val_loss: 2.2222 - val_accuracy: 0.1980\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2263 - accuracy: 0.1953 - val_loss: 2.2106 - val_accuracy: 0.2134\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2110 - accuracy: 0.2022 - val_loss: 2.1869 - val_accuracy: 0.2261\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1781 - accuracy: 0.2193 - val_loss: 2.1414 - val_accuracy: 0.2578\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1075 - accuracy: 0.2591 - val_loss: 2.0503 - val_accuracy: 0.3011\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.9936 - accuracy: 0.3249 - val_loss: 1.9288 - val_accuracy: 0.3543\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.8550 - accuracy: 0.3921 - val_loss: 1.7950 - val_accuracy: 0.4096\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.7175 - accuracy: 0.4507 - val_loss: 1.6760 - val_accuracy: 0.4610\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2515 - accuracy: 0.1826 - val_loss: 2.2344 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2426 - accuracy: 0.1891 - val_loss: 2.2332 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2422 - accuracy: 0.1890 - val_loss: 2.2329 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2409 - accuracy: 0.1892 - val_loss: 2.2329 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2402 - accuracy: 0.1892 - val_loss: 2.2322 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2393 - accuracy: 0.1891 - val_loss: 2.2304 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2391 - accuracy: 0.1892 - val_loss: 2.2286 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2382 - accuracy: 0.1891 - val_loss: 2.2284 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2377 - accuracy: 0.1891 - val_loss: 2.2271 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2370 - accuracy: 0.1890 - val_loss: 2.2260 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2685 - accuracy: 0.1680 - val_loss: 2.2474 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2493 - accuracy: 0.1870 - val_loss: 2.2436 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2469 - accuracy: 0.1880 - val_loss: 2.2411 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2453 - accuracy: 0.1886 - val_loss: 2.2401 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2438 - accuracy: 0.1888 - val_loss: 2.2387 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2430 - accuracy: 0.1886 - val_loss: 2.2378 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2418 - accuracy: 0.1889 - val_loss: 2.2357 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2408 - accuracy: 0.1890 - val_loss: 2.2343 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2407 - accuracy: 0.1892 - val_loss: 2.2320 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2387 - accuracy: 0.1893 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2528 - accuracy: 0.1832 - val_loss: 2.2266 - val_accuracy: 0.1961\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2259 - accuracy: 0.2037 - val_loss: 2.1767 - val_accuracy: 0.2379\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.1743 - accuracy: 0.2416 - val_loss: 2.1171 - val_accuracy: 0.2480\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1019 - accuracy: 0.2795 - val_loss: 2.0154 - val_accuracy: 0.3335\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.0090 - accuracy: 0.3290 - val_loss: 1.9136 - val_accuracy: 0.3690\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.9080 - accuracy: 0.3728 - val_loss: 1.7987 - val_accuracy: 0.4304\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.8085 - accuracy: 0.4055 - val_loss: 1.7197 - val_accuracy: 0.4395\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7203 - accuracy: 0.4359 - val_loss: 1.6446 - val_accuracy: 0.4857\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.6445 - accuracy: 0.4611 - val_loss: 1.5644 - val_accuracy: 0.5369\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 1.5857 - accuracy: 0.4828 - val_loss: 1.5154 - val_accuracy: 0.5426\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.3057 - accuracy: 0.1516 - val_loss: 2.2392 - val_accuracy: 0.1901\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2687 - accuracy: 0.1700 - val_loss: 2.2350 - val_accuracy: 0.1941\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2604 - accuracy: 0.1777 - val_loss: 2.2335 - val_accuracy: 0.1967\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2572 - accuracy: 0.1799 - val_loss: 2.2327 - val_accuracy: 0.1970\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2530 - accuracy: 0.1835 - val_loss: 2.2309 - val_accuracy: 0.1974\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2513 - accuracy: 0.1834 - val_loss: 2.2302 - val_accuracy: 0.1969\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2499 - accuracy: 0.1847 - val_loss: 2.2303 - val_accuracy: 0.1965\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2480 - accuracy: 0.1865 - val_loss: 2.2289 - val_accuracy: 0.1963\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2463 - accuracy: 0.1869 - val_loss: 2.2284 - val_accuracy: 0.1965\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2458 - accuracy: 0.1877 - val_loss: 2.2271 - val_accuracy: 0.1964\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2458 - accuracy: 0.1857 - val_loss: 2.2332 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2387 - accuracy: 0.1895 - val_loss: 2.2308 - val_accuracy: 0.1963\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2337 - accuracy: 0.1907 - val_loss: 2.2274 - val_accuracy: 0.1964\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2285 - accuracy: 0.1927 - val_loss: 2.2233 - val_accuracy: 0.1993\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2224 - accuracy: 0.1975 - val_loss: 2.2157 - val_accuracy: 0.1993\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2152 - accuracy: 0.2020 - val_loss: 2.2104 - val_accuracy: 0.2099\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2069 - accuracy: 0.2061 - val_loss: 2.2078 - val_accuracy: 0.2212\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1975 - accuracy: 0.2122 - val_loss: 2.2006 - val_accuracy: 0.2017\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1865 - accuracy: 0.2200 - val_loss: 2.1881 - val_accuracy: 0.2301\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1729 - accuracy: 0.2295 - val_loss: 2.1792 - val_accuracy: 0.2230\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2445 - accuracy: 0.1871 - val_loss: 2.2336 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2364 - accuracy: 0.1914 - val_loss: 2.2315 - val_accuracy: 0.1962\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2300 - accuracy: 0.1958 - val_loss: 2.2256 - val_accuracy: 0.2059\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2230 - accuracy: 0.2012 - val_loss: 2.2226 - val_accuracy: 0.2083\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2152 - accuracy: 0.2076 - val_loss: 2.2219 - val_accuracy: 0.2013\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2071 - accuracy: 0.2115 - val_loss: 2.2178 - val_accuracy: 0.2104\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1990 - accuracy: 0.2181 - val_loss: 2.2164 - val_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1910 - accuracy: 0.2222 - val_loss: 2.2147 - val_accuracy: 0.2177\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1840 - accuracy: 0.2268 - val_loss: 2.2144 - val_accuracy: 0.2246\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1778 - accuracy: 0.2314 - val_loss: 2.2205 - val_accuracy: 0.2122\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2496 - accuracy: 0.1808 - val_loss: 2.2343 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2418 - accuracy: 0.1890 - val_loss: 2.2331 - val_accuracy: 0.1958\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2399 - accuracy: 0.1894 - val_loss: 2.2311 - val_accuracy: 0.1958\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2390 - accuracy: 0.1890 - val_loss: 2.2297 - val_accuracy: 0.1958\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2373 - accuracy: 0.1894 - val_loss: 2.2278 - val_accuracy: 0.1963\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2363 - accuracy: 0.1892 - val_loss: 2.2265 - val_accuracy: 0.1970\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2345 - accuracy: 0.1885 - val_loss: 2.2244 - val_accuracy: 0.1961\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2329 - accuracy: 0.1894 - val_loss: 2.2234 - val_accuracy: 0.1973\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2316 - accuracy: 0.1892 - val_loss: 2.2230 - val_accuracy: 0.1977\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2298 - accuracy: 0.1901 - val_loss: 2.2200 - val_accuracy: 0.1967\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2544 - accuracy: 0.1777 - val_loss: 2.2348 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2455 - accuracy: 0.1865 - val_loss: 2.2301 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2421 - accuracy: 0.1870 - val_loss: 2.2280 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2373 - accuracy: 0.1882 - val_loss: 2.2217 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2293 - accuracy: 0.1897 - val_loss: 2.2113 - val_accuracy: 0.1960\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2120 - accuracy: 0.1949 - val_loss: 2.1796 - val_accuracy: 0.2018\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.1582 - accuracy: 0.2203 - val_loss: 2.0883 - val_accuracy: 0.2454\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.0299 - accuracy: 0.2863 - val_loss: 1.8809 - val_accuracy: 0.3680\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 1.8753 - accuracy: 0.3540 - val_loss: 1.7112 - val_accuracy: 0.4068\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 1.7395 - accuracy: 0.4056 - val_loss: 1.6345 - val_accuracy: 0.4610\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2685 - accuracy: 0.1666 - val_loss: 2.2430 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2469 - accuracy: 0.1888 - val_loss: 2.2369 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2437 - accuracy: 0.1886 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2426 - accuracy: 0.1888 - val_loss: 2.2337 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2414 - accuracy: 0.1891 - val_loss: 2.2322 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2404 - accuracy: 0.1890 - val_loss: 2.2309 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2395 - accuracy: 0.1891 - val_loss: 2.2298 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2385 - accuracy: 0.1891 - val_loss: 2.2295 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2389 - accuracy: 0.1891 - val_loss: 2.2287 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2379 - accuracy: 0.1891 - val_loss: 2.2274 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2624 - accuracy: 0.1809 - val_loss: 2.2397 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2485 - accuracy: 0.1862 - val_loss: 2.2370 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2456 - accuracy: 0.1878 - val_loss: 2.2346 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2437 - accuracy: 0.1879 - val_loss: 2.2317 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2420 - accuracy: 0.1882 - val_loss: 2.2313 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2391 - accuracy: 0.1889 - val_loss: 2.2250 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2355 - accuracy: 0.1891 - val_loss: 2.2238 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2327 - accuracy: 0.1899 - val_loss: 2.2196 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2261 - accuracy: 0.1895 - val_loss: 2.2065 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2158 - accuracy: 0.1894 - val_loss: 2.1950 - val_accuracy: 0.1968\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2567 - accuracy: 0.1819 - val_loss: 2.2392 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2448 - accuracy: 0.1881 - val_loss: 2.2372 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2428 - accuracy: 0.1891 - val_loss: 2.2358 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2415 - accuracy: 0.1887 - val_loss: 2.2347 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2406 - accuracy: 0.1892 - val_loss: 2.2332 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2393 - accuracy: 0.1896 - val_loss: 2.2311 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2379 - accuracy: 0.1899 - val_loss: 2.2299 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2369 - accuracy: 0.1897 - val_loss: 2.2272 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2351 - accuracy: 0.1903 - val_loss: 2.2261 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2339 - accuracy: 0.1908 - val_loss: 2.2238 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2607 - accuracy: 0.1668 - val_loss: 2.2349 - val_accuracy: 0.1957\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2483 - accuracy: 0.1850 - val_loss: 2.2329 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2471 - accuracy: 0.1853 - val_loss: 2.2324 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2451 - accuracy: 0.1873 - val_loss: 2.2310 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2443 - accuracy: 0.1870 - val_loss: 2.2300 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2423 - accuracy: 0.1877 - val_loss: 2.2287 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2415 - accuracy: 0.1884 - val_loss: 2.2274 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2400 - accuracy: 0.1889 - val_loss: 2.2254 - val_accuracy: 0.1960\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2382 - accuracy: 0.1898 - val_loss: 2.2257 - val_accuracy: 0.1968\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2371 - accuracy: 0.1885 - val_loss: 2.2236 - val_accuracy: 0.1968\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2558 - accuracy: 0.1807 - val_loss: 2.2475 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2430 - accuracy: 0.1889 - val_loss: 2.2458 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2420 - accuracy: 0.1892 - val_loss: 2.2459 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2412 - accuracy: 0.1890 - val_loss: 2.2443 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2403 - accuracy: 0.1893 - val_loss: 2.2439 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2393 - accuracy: 0.1890 - val_loss: 2.2414 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2390 - accuracy: 0.1890 - val_loss: 2.2408 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2381 - accuracy: 0.1890 - val_loss: 2.2391 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2373 - accuracy: 0.1890 - val_loss: 2.2405 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2368 - accuracy: 0.1891 - val_loss: 2.2382 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2904 - accuracy: 0.1236 - val_loss: 2.2532 - val_accuracy: 0.1633\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2554 - accuracy: 0.1758 - val_loss: 2.2353 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2504 - accuracy: 0.1837 - val_loss: 2.2336 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2480 - accuracy: 0.1871 - val_loss: 2.2324 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2467 - accuracy: 0.1879 - val_loss: 2.2324 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2447 - accuracy: 0.1886 - val_loss: 2.2303 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2434 - accuracy: 0.1887 - val_loss: 2.2293 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2419 - accuracy: 0.1892 - val_loss: 2.2278 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2416 - accuracy: 0.1892 - val_loss: 2.2271 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2411 - accuracy: 0.1888 - val_loss: 2.2258 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 7s 8ms/step - loss: 2.2684 - accuracy: 0.1705 - val_loss: 2.2404 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2524 - accuracy: 0.1891 - val_loss: 2.2369 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2471 - accuracy: 0.1889 - val_loss: 2.2321 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2436 - accuracy: 0.1892 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2398 - accuracy: 0.1892 - val_loss: 2.2262 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2315 - accuracy: 0.1892 - val_loss: 2.2073 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2134 - accuracy: 0.1892 - val_loss: 2.1694 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.1756 - accuracy: 0.1892 - val_loss: 2.1394 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.1304 - accuracy: 0.1892 - val_loss: 2.0630 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.0955 - accuracy: 0.1913 - val_loss: 2.0501 - val_accuracy: 0.2278\n",
            "1\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2582 - accuracy: 0.1769 - val_loss: 2.2286 - val_accuracy: 0.2018\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2316 - accuracy: 0.1994 - val_loss: 2.2058 - val_accuracy: 0.2210\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2077 - accuracy: 0.2169 - val_loss: 2.1797 - val_accuracy: 0.2239\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1791 - accuracy: 0.2331 - val_loss: 2.1434 - val_accuracy: 0.2715\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1426 - accuracy: 0.2546 - val_loss: 2.1026 - val_accuracy: 0.2804\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1017 - accuracy: 0.2763 - val_loss: 2.0577 - val_accuracy: 0.2971\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0579 - accuracy: 0.2945 - val_loss: 2.0068 - val_accuracy: 0.3158\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0098 - accuracy: 0.3140 - val_loss: 1.9581 - val_accuracy: 0.3425\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9600 - accuracy: 0.3370 - val_loss: 1.9085 - val_accuracy: 0.3644\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9135 - accuracy: 0.3585 - val_loss: 1.8643 - val_accuracy: 0.4098\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2590 - accuracy: 0.1825 - val_loss: 2.2373 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2487 - accuracy: 0.1863 - val_loss: 2.2322 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2451 - accuracy: 0.1880 - val_loss: 2.2294 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2415 - accuracy: 0.1885 - val_loss: 2.2245 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2369 - accuracy: 0.1893 - val_loss: 2.2185 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2279 - accuracy: 0.1899 - val_loss: 2.2056 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2086 - accuracy: 0.1907 - val_loss: 2.1737 - val_accuracy: 0.2028\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.1681 - accuracy: 0.1955 - val_loss: 2.1096 - val_accuracy: 0.2127\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.1157 - accuracy: 0.2117 - val_loss: 2.0502 - val_accuracy: 0.2389\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.0580 - accuracy: 0.2460 - val_loss: 1.9760 - val_accuracy: 0.3056\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2852 - accuracy: 0.1437 - val_loss: 2.2572 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2637 - accuracy: 0.1789 - val_loss: 2.2437 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2549 - accuracy: 0.1834 - val_loss: 2.2365 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2504 - accuracy: 0.1846 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2436 - accuracy: 0.1869 - val_loss: 2.2210 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2340 - accuracy: 0.1890 - val_loss: 2.2068 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2210 - accuracy: 0.1907 - val_loss: 2.1873 - val_accuracy: 0.1961\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1995 - accuracy: 0.1952 - val_loss: 2.1605 - val_accuracy: 0.1979\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1733 - accuracy: 0.1996 - val_loss: 2.1197 - val_accuracy: 0.2118\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1387 - accuracy: 0.2126 - val_loss: 2.0702 - val_accuracy: 0.2328\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2487 - accuracy: 0.1862 - val_loss: 2.2442 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2411 - accuracy: 0.1893 - val_loss: 2.2420 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2392 - accuracy: 0.1893 - val_loss: 2.2410 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2378 - accuracy: 0.1892 - val_loss: 2.2393 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2362 - accuracy: 0.1893 - val_loss: 2.2365 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2335 - accuracy: 0.1898 - val_loss: 2.2323 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2299 - accuracy: 0.1906 - val_loss: 2.2291 - val_accuracy: 0.2015\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2244 - accuracy: 0.1941 - val_loss: 2.2212 - val_accuracy: 0.2110\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2136 - accuracy: 0.1993 - val_loss: 2.2026 - val_accuracy: 0.2134\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.1944 - accuracy: 0.2112 - val_loss: 2.1751 - val_accuracy: 0.2358\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2660 - accuracy: 0.1773 - val_loss: 2.2345 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2497 - accuracy: 0.1856 - val_loss: 2.2301 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2435 - accuracy: 0.1868 - val_loss: 2.2237 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2368 - accuracy: 0.1876 - val_loss: 2.2140 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2261 - accuracy: 0.1889 - val_loss: 2.1962 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2082 - accuracy: 0.1898 - val_loss: 2.1725 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1817 - accuracy: 0.1904 - val_loss: 2.1324 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1472 - accuracy: 0.1923 - val_loss: 2.0938 - val_accuracy: 0.1991\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1135 - accuracy: 0.2028 - val_loss: 2.0548 - val_accuracy: 0.2212\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0820 - accuracy: 0.2253 - val_loss: 2.0193 - val_accuracy: 0.2714\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2656 - accuracy: 0.1693 - val_loss: 2.2391 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2527 - accuracy: 0.1826 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2469 - accuracy: 0.1858 - val_loss: 2.2274 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2409 - accuracy: 0.1877 - val_loss: 2.2227 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2317 - accuracy: 0.1911 - val_loss: 2.2058 - val_accuracy: 0.2097\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2151 - accuracy: 0.1981 - val_loss: 2.1789 - val_accuracy: 0.2179\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1900 - accuracy: 0.2062 - val_loss: 2.1389 - val_accuracy: 0.2377\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1489 - accuracy: 0.2213 - val_loss: 2.0879 - val_accuracy: 0.2731\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0992 - accuracy: 0.2461 - val_loss: 2.0122 - val_accuracy: 0.2890\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0409 - accuracy: 0.2743 - val_loss: 1.9439 - val_accuracy: 0.3230\n",
            "0.9\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2894 - accuracy: 0.1666 - val_loss: 2.2491 - val_accuracy: 0.1794\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2732 - accuracy: 0.1714 - val_loss: 2.2426 - val_accuracy: 0.1938\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2644 - accuracy: 0.1759 - val_loss: 2.2384 - val_accuracy: 0.1925\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2580 - accuracy: 0.1807 - val_loss: 2.2351 - val_accuracy: 0.1966\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2543 - accuracy: 0.1811 - val_loss: 2.2322 - val_accuracy: 0.1986\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2508 - accuracy: 0.1843 - val_loss: 2.2307 - val_accuracy: 0.1982\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2478 - accuracy: 0.1845 - val_loss: 2.2287 - val_accuracy: 0.1979\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2442 - accuracy: 0.1864 - val_loss: 2.2267 - val_accuracy: 0.1977\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2414 - accuracy: 0.1878 - val_loss: 2.2219 - val_accuracy: 0.2004\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2384 - accuracy: 0.1888 - val_loss: 2.2203 - val_accuracy: 0.2146\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2505 - accuracy: 0.1829 - val_loss: 2.2412 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2436 - accuracy: 0.1873 - val_loss: 2.2391 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2405 - accuracy: 0.1888 - val_loss: 2.2367 - val_accuracy: 0.1960\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2373 - accuracy: 0.1899 - val_loss: 2.2365 - val_accuracy: 0.2023\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2336 - accuracy: 0.1918 - val_loss: 2.2318 - val_accuracy: 0.1999\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2291 - accuracy: 0.1949 - val_loss: 2.2269 - val_accuracy: 0.2100\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2239 - accuracy: 0.1975 - val_loss: 2.2188 - val_accuracy: 0.2097\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2167 - accuracy: 0.2021 - val_loss: 2.2099 - val_accuracy: 0.2140\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2059 - accuracy: 0.2087 - val_loss: 2.2065 - val_accuracy: 0.2303\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1915 - accuracy: 0.2175 - val_loss: 2.1836 - val_accuracy: 0.2470\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2495 - accuracy: 0.1839 - val_loss: 2.2394 - val_accuracy: 0.2014\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2390 - accuracy: 0.1908 - val_loss: 2.2299 - val_accuracy: 0.2101\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2280 - accuracy: 0.1968 - val_loss: 2.2208 - val_accuracy: 0.2054\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2199 - accuracy: 0.2025 - val_loss: 2.2153 - val_accuracy: 0.2213\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2111 - accuracy: 0.2084 - val_loss: 2.2089 - val_accuracy: 0.2139\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2028 - accuracy: 0.2124 - val_loss: 2.2057 - val_accuracy: 0.2207\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1945 - accuracy: 0.2179 - val_loss: 2.1992 - val_accuracy: 0.2091\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1855 - accuracy: 0.2226 - val_loss: 2.1918 - val_accuracy: 0.2286\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1770 - accuracy: 0.2286 - val_loss: 2.1890 - val_accuracy: 0.2190\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1708 - accuracy: 0.2305 - val_loss: 2.1861 - val_accuracy: 0.2142\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2690 - accuracy: 0.1642 - val_loss: 2.2354 - val_accuracy: 0.1957\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2483 - accuracy: 0.1820 - val_loss: 2.2277 - val_accuracy: 0.1960\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2400 - accuracy: 0.1878 - val_loss: 2.2199 - val_accuracy: 0.1961\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2319 - accuracy: 0.1891 - val_loss: 2.2084 - val_accuracy: 0.1966\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2184 - accuracy: 0.1919 - val_loss: 2.1900 - val_accuracy: 0.1971\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2009 - accuracy: 0.1966 - val_loss: 2.1659 - val_accuracy: 0.2061\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1766 - accuracy: 0.2032 - val_loss: 2.1281 - val_accuracy: 0.2193\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1413 - accuracy: 0.2184 - val_loss: 2.0834 - val_accuracy: 0.2424\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.0975 - accuracy: 0.2435 - val_loss: 2.0315 - val_accuracy: 0.2941\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0486 - accuracy: 0.2748 - val_loss: 1.9741 - val_accuracy: 0.3226\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2449 - accuracy: 0.1884 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2394 - accuracy: 0.1894 - val_loss: 2.2300 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2358 - accuracy: 0.1900 - val_loss: 2.2271 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2301 - accuracy: 0.1911 - val_loss: 2.2208 - val_accuracy: 0.2020\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2222 - accuracy: 0.1940 - val_loss: 2.2141 - val_accuracy: 0.2116\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2117 - accuracy: 0.1992 - val_loss: 2.2057 - val_accuracy: 0.1991\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1987 - accuracy: 0.2052 - val_loss: 2.1966 - val_accuracy: 0.2167\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1838 - accuracy: 0.2163 - val_loss: 2.1799 - val_accuracy: 0.2133\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1636 - accuracy: 0.2292 - val_loss: 2.1618 - val_accuracy: 0.2489\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1342 - accuracy: 0.2491 - val_loss: 2.1252 - val_accuracy: 0.2625\n",
            "0.9\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 5ms/step - loss: 2.2626 - accuracy: 0.1739 - val_loss: 2.2316 - val_accuracy: 0.2045\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2428 - accuracy: 0.1893 - val_loss: 2.2210 - val_accuracy: 0.2054\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2320 - accuracy: 0.1990 - val_loss: 2.2080 - val_accuracy: 0.2097\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2163 - accuracy: 0.2072 - val_loss: 2.1896 - val_accuracy: 0.2459\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1982 - accuracy: 0.2182 - val_loss: 2.1684 - val_accuracy: 0.2308\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1760 - accuracy: 0.2320 - val_loss: 2.1417 - val_accuracy: 0.2420\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1501 - accuracy: 0.2468 - val_loss: 2.1149 - val_accuracy: 0.2691\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1220 - accuracy: 0.2637 - val_loss: 2.0852 - val_accuracy: 0.2799\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0927 - accuracy: 0.2799 - val_loss: 2.0540 - val_accuracy: 0.2995\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0617 - accuracy: 0.2946 - val_loss: 2.0210 - val_accuracy: 0.3222\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2439 - accuracy: 0.1867 - val_loss: 2.2338 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2378 - accuracy: 0.1894 - val_loss: 2.2292 - val_accuracy: 0.1965\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2324 - accuracy: 0.1920 - val_loss: 2.2273 - val_accuracy: 0.1968\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2260 - accuracy: 0.1940 - val_loss: 2.2208 - val_accuracy: 0.1999\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2183 - accuracy: 0.2001 - val_loss: 2.2211 - val_accuracy: 0.2179\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2114 - accuracy: 0.2062 - val_loss: 2.2173 - val_accuracy: 0.2217\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2037 - accuracy: 0.2110 - val_loss: 2.2090 - val_accuracy: 0.2159\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1963 - accuracy: 0.2154 - val_loss: 2.2097 - val_accuracy: 0.2340\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1896 - accuracy: 0.2201 - val_loss: 2.2092 - val_accuracy: 0.2355\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1820 - accuracy: 0.2258 - val_loss: 2.1988 - val_accuracy: 0.2302\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2620 - accuracy: 0.1726 - val_loss: 2.2439 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2521 - accuracy: 0.1822 - val_loss: 2.2398 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2492 - accuracy: 0.1833 - val_loss: 2.2380 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2470 - accuracy: 0.1850 - val_loss: 2.2366 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2451 - accuracy: 0.1858 - val_loss: 2.2341 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2439 - accuracy: 0.1853 - val_loss: 2.2327 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2420 - accuracy: 0.1862 - val_loss: 2.2296 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 4ms/step - loss: 2.2407 - accuracy: 0.1861 - val_loss: 2.2277 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2394 - accuracy: 0.1873 - val_loss: 2.2265 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2380 - accuracy: 0.1876 - val_loss: 2.2257 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 7ms/step - loss: 2.2769 - accuracy: 0.1533 - val_loss: 2.2437 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2467 - accuracy: 0.1871 - val_loss: 2.2353 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2443 - accuracy: 0.1879 - val_loss: 2.2343 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2430 - accuracy: 0.1884 - val_loss: 2.2329 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2424 - accuracy: 0.1891 - val_loss: 2.2320 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2405 - accuracy: 0.1891 - val_loss: 2.2306 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2394 - accuracy: 0.1892 - val_loss: 2.2281 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2373 - accuracy: 0.1891 - val_loss: 2.2254 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2363 - accuracy: 0.1893 - val_loss: 2.2234 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2351 - accuracy: 0.1892 - val_loss: 2.2221 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2457 - accuracy: 0.1870 - val_loss: 2.2336 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2405 - accuracy: 0.1893 - val_loss: 2.2300 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2361 - accuracy: 0.1906 - val_loss: 2.2242 - val_accuracy: 0.1961\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2291 - accuracy: 0.1940 - val_loss: 2.2138 - val_accuracy: 0.2142\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2149 - accuracy: 0.2031 - val_loss: 2.1910 - val_accuracy: 0.2419\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.1828 - accuracy: 0.2222 - val_loss: 2.1400 - val_accuracy: 0.2360\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.1041 - accuracy: 0.2699 - val_loss: 2.0112 - val_accuracy: 0.3422\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 1.9536 - accuracy: 0.3536 - val_loss: 1.8392 - val_accuracy: 0.4039\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 1.7726 - accuracy: 0.4381 - val_loss: 1.6740 - val_accuracy: 0.4864\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 1.6176 - accuracy: 0.4991 - val_loss: 1.5505 - val_accuracy: 0.5238\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2511 - accuracy: 0.1841 - val_loss: 2.2361 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2424 - accuracy: 0.1891 - val_loss: 2.2327 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2360 - accuracy: 0.1921 - val_loss: 2.2211 - val_accuracy: 0.1960\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2257 - accuracy: 0.1960 - val_loss: 2.2119 - val_accuracy: 0.2115\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2045 - accuracy: 0.2076 - val_loss: 2.1829 - val_accuracy: 0.2404\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1633 - accuracy: 0.2357 - val_loss: 2.1348 - val_accuracy: 0.2891\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.0909 - accuracy: 0.2839 - val_loss: 2.0478 - val_accuracy: 0.3430\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 1.9784 - accuracy: 0.3403 - val_loss: 1.9141 - val_accuracy: 0.3977\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.8450 - accuracy: 0.3897 - val_loss: 1.7802 - val_accuracy: 0.4613\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 1.7220 - accuracy: 0.4362 - val_loss: 1.6539 - val_accuracy: 0.5129\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2528 - accuracy: 0.1801 - val_loss: 2.2515 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2431 - accuracy: 0.1886 - val_loss: 2.2483 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2413 - accuracy: 0.1890 - val_loss: 2.2496 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2393 - accuracy: 0.1891 - val_loss: 2.2471 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2377 - accuracy: 0.1898 - val_loss: 2.2438 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2356 - accuracy: 0.1894 - val_loss: 2.2433 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2332 - accuracy: 0.1898 - val_loss: 2.2414 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2312 - accuracy: 0.1904 - val_loss: 2.2396 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2280 - accuracy: 0.1908 - val_loss: 2.2349 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2240 - accuracy: 0.1929 - val_loss: 2.2330 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2523 - accuracy: 0.1870 - val_loss: 2.2508 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2459 - accuracy: 0.1885 - val_loss: 2.2503 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2443 - accuracy: 0.1885 - val_loss: 2.2467 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2434 - accuracy: 0.1888 - val_loss: 2.2462 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2431 - accuracy: 0.1885 - val_loss: 2.2450 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2414 - accuracy: 0.1888 - val_loss: 2.2438 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2404 - accuracy: 0.1888 - val_loss: 2.2456 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2402 - accuracy: 0.1890 - val_loss: 2.2425 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2381 - accuracy: 0.1892 - val_loss: 2.2399 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2375 - accuracy: 0.1891 - val_loss: 2.2366 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2460 - accuracy: 0.1871 - val_loss: 2.2331 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2384 - accuracy: 0.1905 - val_loss: 2.2265 - val_accuracy: 0.1958\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2309 - accuracy: 0.1925 - val_loss: 2.2222 - val_accuracy: 0.1999\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2227 - accuracy: 0.1966 - val_loss: 2.2123 - val_accuracy: 0.1971\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2132 - accuracy: 0.2010 - val_loss: 2.2039 - val_accuracy: 0.2068\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2024 - accuracy: 0.2072 - val_loss: 2.1952 - val_accuracy: 0.2320\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1917 - accuracy: 0.2146 - val_loss: 2.1859 - val_accuracy: 0.2147\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1800 - accuracy: 0.2220 - val_loss: 2.1747 - val_accuracy: 0.2260\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1688 - accuracy: 0.2298 - val_loss: 2.1650 - val_accuracy: 0.2397\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1560 - accuracy: 0.2380 - val_loss: 2.1531 - val_accuracy: 0.2483\n",
            "0.8\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 6s 8ms/step - loss: 2.2599 - accuracy: 0.1711 - val_loss: 2.2316 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2431 - accuracy: 0.1884 - val_loss: 2.2301 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2425 - accuracy: 0.1888 - val_loss: 2.2300 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2415 - accuracy: 0.1891 - val_loss: 2.2292 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2407 - accuracy: 0.1890 - val_loss: 2.2279 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2400 - accuracy: 0.1890 - val_loss: 2.2269 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2396 - accuracy: 0.1892 - val_loss: 2.2262 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2386 - accuracy: 0.1890 - val_loss: 2.2248 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.2382 - accuracy: 0.1892 - val_loss: 2.2253 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2378 - accuracy: 0.1892 - val_loss: 2.2241 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2430 - accuracy: 0.1861 - val_loss: 2.2260 - val_accuracy: 0.1957\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2090 - accuracy: 0.2015 - val_loss: 2.1770 - val_accuracy: 0.2429\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1523 - accuracy: 0.2382 - val_loss: 2.1033 - val_accuracy: 0.2646\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0701 - accuracy: 0.2920 - val_loss: 2.0205 - val_accuracy: 0.3457\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.9688 - accuracy: 0.3467 - val_loss: 1.9063 - val_accuracy: 0.3719\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.8627 - accuracy: 0.3928 - val_loss: 1.8079 - val_accuracy: 0.4120\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.7632 - accuracy: 0.4342 - val_loss: 1.7177 - val_accuracy: 0.4587\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.6727 - accuracy: 0.4700 - val_loss: 1.6285 - val_accuracy: 0.4840\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.5911 - accuracy: 0.5019 - val_loss: 1.5499 - val_accuracy: 0.5094\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 1.5203 - accuracy: 0.5270 - val_loss: 1.5314 - val_accuracy: 0.5231\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2613 - accuracy: 0.1750 - val_loss: 2.2469 - val_accuracy: 0.1958\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2471 - accuracy: 0.1865 - val_loss: 2.2447 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2462 - accuracy: 0.1878 - val_loss: 2.2433 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2443 - accuracy: 0.1876 - val_loss: 2.2422 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2427 - accuracy: 0.1881 - val_loss: 2.2400 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2416 - accuracy: 0.1891 - val_loss: 2.2381 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2404 - accuracy: 0.1893 - val_loss: 2.2365 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2393 - accuracy: 0.1888 - val_loss: 2.2356 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2382 - accuracy: 0.1891 - val_loss: 2.2355 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2365 - accuracy: 0.1892 - val_loss: 2.2309 - val_accuracy: 0.1959\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2419 - accuracy: 0.1888 - val_loss: 2.2287 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2283 - accuracy: 0.1945 - val_loss: 2.2158 - val_accuracy: 0.2233\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.2129 - accuracy: 0.2018 - val_loss: 2.2051 - val_accuracy: 0.1965\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1946 - accuracy: 0.2141 - val_loss: 2.1864 - val_accuracy: 0.2152\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1740 - accuracy: 0.2288 - val_loss: 2.1684 - val_accuracy: 0.2287\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1514 - accuracy: 0.2447 - val_loss: 2.1473 - val_accuracy: 0.2712\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.1250 - accuracy: 0.2643 - val_loss: 2.1224 - val_accuracy: 0.2658\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0968 - accuracy: 0.2847 - val_loss: 2.0960 - val_accuracy: 0.2981\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0669 - accuracy: 0.3026 - val_loss: 2.0654 - val_accuracy: 0.3212\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 2s 4ms/step - loss: 2.0352 - accuracy: 0.3225 - val_loss: 2.0370 - val_accuracy: 0.3181\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 6ms/step - loss: 2.2463 - accuracy: 0.1885 - val_loss: 2.2340 - val_accuracy: 0.1956\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2370 - accuracy: 0.1902 - val_loss: 2.2291 - val_accuracy: 0.1960\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2319 - accuracy: 0.1911 - val_loss: 2.2239 - val_accuracy: 0.1961\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2261 - accuracy: 0.1932 - val_loss: 2.2179 - val_accuracy: 0.2012\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2192 - accuracy: 0.1951 - val_loss: 2.2113 - val_accuracy: 0.2004\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2109 - accuracy: 0.1984 - val_loss: 2.2060 - val_accuracy: 0.2178\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1999 - accuracy: 0.2043 - val_loss: 2.1925 - val_accuracy: 0.2099\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1885 - accuracy: 0.2082 - val_loss: 2.1816 - val_accuracy: 0.2177\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1747 - accuracy: 0.2159 - val_loss: 2.1715 - val_accuracy: 0.2381\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1583 - accuracy: 0.2263 - val_loss: 2.1532 - val_accuracy: 0.2365\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 5s 7ms/step - loss: 2.2515 - accuracy: 0.1839 - val_loss: 2.2351 - val_accuracy: 0.1960\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2426 - accuracy: 0.1896 - val_loss: 2.2303 - val_accuracy: 0.1963\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2374 - accuracy: 0.1899 - val_loss: 2.2260 - val_accuracy: 0.1974\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2326 - accuracy: 0.1927 - val_loss: 2.2194 - val_accuracy: 0.1984\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2264 - accuracy: 0.1951 - val_loss: 2.2120 - val_accuracy: 0.1997\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2192 - accuracy: 0.1997 - val_loss: 2.2033 - val_accuracy: 0.2112\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.2110 - accuracy: 0.2055 - val_loss: 2.1948 - val_accuracy: 0.2226\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1987 - accuracy: 0.2135 - val_loss: 2.1824 - val_accuracy: 0.2299\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1849 - accuracy: 0.2229 - val_loss: 2.1653 - val_accuracy: 0.2342\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 5ms/step - loss: 2.1680 - accuracy: 0.2300 - val_loss: 2.1487 - val_accuracy: 0.2517\n",
            "0.8\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 7s 8ms/step - loss: 2.2620 - accuracy: 0.1750 - val_loss: 2.2328 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2473 - accuracy: 0.1883 - val_loss: 2.2303 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2434 - accuracy: 0.1889 - val_loss: 2.2325 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2385 - accuracy: 0.1890 - val_loss: 2.2199 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2290 - accuracy: 0.1892 - val_loss: 2.2021 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 6ms/step - loss: 2.2091 - accuracy: 0.1892 - val_loss: 2.1640 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1732 - accuracy: 0.1892 - val_loss: 2.1176 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1369 - accuracy: 0.1899 - val_loss: 2.0775 - val_accuracy: 0.1967\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.1072 - accuracy: 0.1992 - val_loss: 2.0570 - val_accuracy: 0.2261\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 3s 6ms/step - loss: 2.0818 - accuracy: 0.2185 - val_loss: 2.0183 - val_accuracy: 0.2484\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 7s 9ms/step - loss: 2.2615 - accuracy: 0.1680 - val_loss: 2.2337 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2482 - accuracy: 0.1854 - val_loss: 2.2320 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2453 - accuracy: 0.1876 - val_loss: 2.2288 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 8ms/step - loss: 2.2429 - accuracy: 0.1878 - val_loss: 2.2257 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2408 - accuracy: 0.1881 - val_loss: 2.2246 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2383 - accuracy: 0.1887 - val_loss: 2.2219 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2346 - accuracy: 0.1890 - val_loss: 2.2203 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2284 - accuracy: 0.1889 - val_loss: 2.2112 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2215 - accuracy: 0.1897 - val_loss: 2.2039 - val_accuracy: 0.1961\n",
            "Epoch 10/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2119 - accuracy: 0.1907 - val_loss: 2.1905 - val_accuracy: 0.2016\n",
            "Epoch 1/10\n",
            "573/573 [==============================] - 7s 9ms/step - loss: 2.2600 - accuracy: 0.1872 - val_loss: 2.2525 - val_accuracy: 0.1959\n",
            "Epoch 2/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2463 - accuracy: 0.1892 - val_loss: 2.2497 - val_accuracy: 0.1959\n",
            "Epoch 3/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2447 - accuracy: 0.1888 - val_loss: 2.2507 - val_accuracy: 0.1959\n",
            "Epoch 4/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2434 - accuracy: 0.1893 - val_loss: 2.2469 - val_accuracy: 0.1959\n",
            "Epoch 5/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2428 - accuracy: 0.1893 - val_loss: 2.2487 - val_accuracy: 0.1959\n",
            "Epoch 6/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2418 - accuracy: 0.1890 - val_loss: 2.2474 - val_accuracy: 0.1959\n",
            "Epoch 7/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2408 - accuracy: 0.1892 - val_loss: 2.2474 - val_accuracy: 0.1959\n",
            "Epoch 8/10\n",
            "573/573 [==============================] - 4s 8ms/step - loss: 2.2403 - accuracy: 0.1891 - val_loss: 2.2442 - val_accuracy: 0.1959\n",
            "Epoch 9/10\n",
            "573/573 [==============================] - 4s 7ms/step - loss: 2.2397 - accuracy: 0.1892 - val_loss: 2.2438 - val_accuracy: 0.1959\n",
            "Epoch 10/10\n",
            "138/573 [======>.......................] - ETA: 2s - loss: 2.2442 - accuracy: 0.1901"
          ]
        }
      ],
      "source": [
        "#finally we run the meta_qnn_algorithm multiple times with various epsilon values\n",
        "#we start with a large number at epsilon=1 to give it appropriate time to explore-\n",
        "#-before it eventually chooses more 'greedy' options\n",
        "#we decrement epsilon by .1 making the agent more 'greedy' until it reaches 0.1-\n",
        "#-where it should converge to an optimal CNN\n",
        "for i in range(8):\n",
        "  meta_qnn_algorithm(1)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.9)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.8)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.7)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.6)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.5)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.4)\n",
        "for i in range(2):\n",
        "  meta_qnn_algorithm(0.3)\n",
        "for i in range(3):\n",
        "  meta_qnn_algorithm(0.2)\n",
        "for i in range(3):\n",
        "  meta_qnn_algorithm(0.1)"
      ],
      "id": "HDprPwlKxC24"
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_acc) #we print out for the sake of graphing and observing the accuracies of different CNN structures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtClQVjlakZF",
        "outputId": "90d5a67f-37ab-4cb5-a997-ab3c9d8d896d"
      },
      "id": "LtClQVjlakZF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[([(0, 'i', 1), (1, 'c3', 1), (2, 'p1', 1), (3, 'd2', 0)], 0.47157344222068787), ([(0, 'i', 1), (1, 'c1', 1), (2, 'd2', 0), (3, 'd1', 0)], 0.6152427792549133), ([(0, 'i', 1), (1, 'c1', 1), (2, 'c2', 1), (3, 'd1', 0), (4, 'd1', 0)], 0.6437845826148987), ([(0, 'i', 1), (1, 'd2', 0), (2, 'd2', 0), (3, 'd1', 0)], 0.42609095573425293), ([(0, 'i', 1), (1, 'c1', 1), (2, 'c4', 1)], 0.4880915880203247), ([(0, 'i', 1), (1, 'c1', 1), (2, 'd1', 0)], 0.6417102217674255), ([(0, 'i', 1), (1, 'c1', 1), (2, 'c3', 1), (3, 'c3', 1), (4, 'd1', 0)], 0.7429701685905457), ([(0, 'i', 1)], 0.21074062585830688)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Q_table) #we print out the final Q-table for observation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL6Ul2wLbIj0",
        "outputId": "501aed76-8feb-4bd3-c00c-da30a0b1bdc0"
      },
      "id": "WL6Ul2wLbIj0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.12486917 0.12238454 0.14077126 0.18298549 0.1130643  0.11265022\n",
            "  0.14694526 0.130832   0.33637777]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.10012176\n",
            "  0.10012176 0.1        0.12672317]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.12436632]\n",
            " [0.1        0.1        0.10038949 0.1        0.1        0.1\n",
            "  0.1        0.1        0.11391241]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10075488 0.10460602 0.17340449]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10280151 0.10010611 0.15771688]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.10030117 0.1\n",
            "  0.1        0.1        0.10937815]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10291143 0.10208144 0.12265252]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10005474 0.10256301 0.12249881]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.10045157 0.10194642 0.10318077 0.10009214 0.1        0.10009214\n",
            "  0.1        0.1        0.21364924]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.10012276 0.1\n",
            "  0.1        0.1        0.10413323]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.10259545 0.1        0.12456907]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10041584 0.10037291 0.13595694]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.01147833\n",
            "  0.1001128  0.1        0.14544242]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.10073108 0.10162424 0.1499805 ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10150372 0.10154773 0.1305991 ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10031246 0.1        0.17842211]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.10174308 0.14457952]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.10016071 0.10098527 0.10541081]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.10023432 0.1050721  0.12686206]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.10153154 0.14602499]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.1        0.1        0.1        0.1        0.1        0.1\n",
            "  0.1        0.1        0.12573374]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.16467848]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1        0.1        0.1       ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import csv\n",
        "import pickle\n",
        "import ast\n",
        "import json\n",
        "\n",
        "\n",
        "csv_file_path = 'table_failed.csv'\n",
        "\n",
        "np.savetxt(csv_file_path, Q_table, delimiter=\",\")\n",
        "# Now, let's import the CSV file back into another NumPy array\n",
        "Q_values_new = np.genfromtxt(csv_file_path, delimiter=\",\")\n",
        "\n",
        "# Display the imported array\n",
        "print(Q_values_new)\n",
        "'''"
      ],
      "metadata": {
        "id": "NjKaH7NHpnbm"
      },
      "id": "NjKaH7NHpnbm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}